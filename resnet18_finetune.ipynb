{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "D9CwL-fZSx89"
      },
      "outputs": [],
      "source": [
        "#lets try and use torch instead\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import SGD\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Pa2pj_msScve"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 196 #num classes in stanford cars dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ZLy8BowtSeYx"
      },
      "outputs": [],
      "source": [
        "transforms = transforms.Compose(\n",
        "[\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224))\n",
        "])\n",
        "train = datasets.StanfordCars(\"cars\", split=\"train\", transform=transforms) #download=True if running repo for the first time\n",
        "test = datasets.StanfordCars(\"cars\", split=\"test\", transform=transforms)#download=True if running repo for the first time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Unm0u8HySnoW"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train, batch_size = 10, shuffle = True)\n",
        "test_loader = DataLoader(test, batch_size = 10, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "z5ONHy2iSqp5"
      },
      "outputs": [],
      "source": [
        "resnet = models.resnet18(weights= \"DEFAULT\")\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False #freeze all layers for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "9jvVxEdfSrc1"
      },
      "outputs": [],
      "source": [
        "#lets set the output layer to be our 196 classes\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
        "resnet.fc = nn.Linear(512, NUM_CLASSES)  #lets just do a basic linear classification head as a baseline and move from there\n",
        "resnet.to(device)\n",
        "optimizer = SGD(resnet.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "#device = torch.device('cpu')\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D90rSPowT5f5",
        "outputId": "b37f7ed8-6948-4974-9767-bea67be4f547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3HdEyAvSsXw",
        "outputId": "a07de8d4-3c4f-45be-d95f-57eff5009ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "\n",
            "Epoch [1/50], Step [0/815], Loss: 5.4213\n",
            "Epoch [1/50], Step [20/815], Loss: 5.3592\n",
            "Epoch [1/50], Step [40/815], Loss: 5.3224\n",
            "Epoch [1/50], Step [60/815], Loss: 5.2684\n",
            "Epoch [1/50], Step [80/815], Loss: 5.4403\n",
            "Epoch [1/50], Step [100/815], Loss: 5.4976\n",
            "Epoch [1/50], Step [120/815], Loss: 5.6152\n",
            "Epoch [1/50], Step [140/815], Loss: 5.1116\n",
            "Epoch [1/50], Step [160/815], Loss: 5.4164\n",
            "Epoch [1/50], Step [180/815], Loss: 5.3592\n",
            "Epoch [1/50], Step [200/815], Loss: 5.1971\n",
            "Epoch [1/50], Step [220/815], Loss: 5.0910\n",
            "Epoch [1/50], Step [240/815], Loss: 5.2815\n",
            "Epoch [1/50], Step [260/815], Loss: 5.5753\n",
            "Epoch [1/50], Step [280/815], Loss: 5.0966\n",
            "Epoch [1/50], Step [300/815], Loss: 5.0963\n",
            "Epoch [1/50], Step [320/815], Loss: 5.3696\n",
            "Epoch [1/50], Step [340/815], Loss: 5.2692\n",
            "Epoch [1/50], Step [360/815], Loss: 5.4746\n",
            "Epoch [1/50], Step [380/815], Loss: 5.3711\n",
            "Epoch [1/50], Step [400/815], Loss: 5.2659\n",
            "Epoch [1/50], Step [420/815], Loss: 5.2017\n",
            "Epoch [1/50], Step [440/815], Loss: 5.2233\n",
            "Epoch [1/50], Step [460/815], Loss: 5.4061\n",
            "Epoch [1/50], Step [480/815], Loss: 5.4846\n",
            "Epoch [1/50], Step [500/815], Loss: 5.2414\n",
            "Epoch [1/50], Step [520/815], Loss: 5.2829\n",
            "Epoch [1/50], Step [540/815], Loss: 5.2422\n",
            "Epoch [1/50], Step [560/815], Loss: 5.1707\n",
            "Epoch [1/50], Step [580/815], Loss: 5.4001\n",
            "Epoch [1/50], Step [600/815], Loss: 5.1964\n",
            "Epoch [1/50], Step [620/815], Loss: 5.3510\n",
            "Epoch [1/50], Step [640/815], Loss: 5.2200\n",
            "Epoch [1/50], Step [660/815], Loss: 5.1675\n",
            "Epoch [1/50], Step [680/815], Loss: 5.2364\n",
            "Epoch [1/50], Step [700/815], Loss: 5.2705\n",
            "Epoch [1/50], Step [720/815], Loss: 5.3218\n",
            "Epoch [1/50], Step [740/815], Loss: 5.3110\n",
            "Epoch [1/50], Step [760/815], Loss: 5.4538\n",
            "Epoch [1/50], Step [780/815], Loss: 5.3444\n",
            "Epoch [1/50], Step [800/815], Loss: 5.1983\n",
            "\n",
            "train-loss: 5.3028, train-acc: 0.9946\n",
            "validation loss: 5.2380, validation acc: 1.3431\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 2\n",
            "\n",
            "Epoch [2/50], Step [0/815], Loss: 5.2977\n",
            "Epoch [2/50], Step [20/815], Loss: 5.2818\n",
            "Epoch [2/50], Step [40/815], Loss: 5.2275\n",
            "Epoch [2/50], Step [60/815], Loss: 5.2131\n",
            "Epoch [2/50], Step [80/815], Loss: 5.4348\n",
            "Epoch [2/50], Step [100/815], Loss: 5.2691\n",
            "Epoch [2/50], Step [120/815], Loss: 4.9253\n",
            "Epoch [2/50], Step [140/815], Loss: 5.2392\n",
            "Epoch [2/50], Step [160/815], Loss: 5.2329\n",
            "Epoch [2/50], Step [180/815], Loss: 5.3459\n",
            "Epoch [2/50], Step [200/815], Loss: 5.0950\n",
            "Epoch [2/50], Step [220/815], Loss: 5.2763\n",
            "Epoch [2/50], Step [240/815], Loss: 5.2407\n",
            "Epoch [2/50], Step [260/815], Loss: 5.2478\n",
            "Epoch [2/50], Step [280/815], Loss: 5.1507\n",
            "Epoch [2/50], Step [300/815], Loss: 5.2927\n",
            "Epoch [2/50], Step [320/815], Loss: 5.1322\n",
            "Epoch [2/50], Step [340/815], Loss: 5.4466\n",
            "Epoch [2/50], Step [360/815], Loss: 5.2997\n",
            "Epoch [2/50], Step [380/815], Loss: 5.1793\n",
            "Epoch [2/50], Step [400/815], Loss: 5.1390\n",
            "Epoch [2/50], Step [420/815], Loss: 5.5138\n",
            "Epoch [2/50], Step [440/815], Loss: 5.0879\n",
            "Epoch [2/50], Step [460/815], Loss: 5.2044\n",
            "Epoch [2/50], Step [480/815], Loss: 5.1919\n",
            "Epoch [2/50], Step [500/815], Loss: 5.0093\n",
            "Epoch [2/50], Step [520/815], Loss: 5.2541\n",
            "Epoch [2/50], Step [540/815], Loss: 5.0251\n",
            "Epoch [2/50], Step [560/815], Loss: 5.1368\n",
            "Epoch [2/50], Step [580/815], Loss: 5.2155\n",
            "Epoch [2/50], Step [600/815], Loss: 5.2916\n",
            "Epoch [2/50], Step [620/815], Loss: 5.2080\n",
            "Epoch [2/50], Step [640/815], Loss: 5.0890\n",
            "Epoch [2/50], Step [660/815], Loss: 5.0865\n",
            "Epoch [2/50], Step [680/815], Loss: 5.1094\n",
            "Epoch [2/50], Step [700/815], Loss: 5.1791\n",
            "Epoch [2/50], Step [720/815], Loss: 5.1565\n",
            "Epoch [2/50], Step [740/815], Loss: 5.0766\n",
            "Epoch [2/50], Step [760/815], Loss: 5.0716\n",
            "Epoch [2/50], Step [780/815], Loss: 5.0431\n",
            "Epoch [2/50], Step [800/815], Loss: 5.1037\n",
            "\n",
            "train-loss: 5.2507, train-acc: 1.7559\n",
            "validation loss: 5.1963, validation acc: 1.9774\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 3\n",
            "\n",
            "Epoch [3/50], Step [0/815], Loss: 5.0710\n",
            "Epoch [3/50], Step [20/815], Loss: 5.0761\n",
            "Epoch [3/50], Step [40/815], Loss: 5.0530\n",
            "Epoch [3/50], Step [60/815], Loss: 5.1024\n",
            "Epoch [3/50], Step [80/815], Loss: 5.0747\n",
            "Epoch [3/50], Step [100/815], Loss: 5.2367\n",
            "Epoch [3/50], Step [120/815], Loss: 5.2422\n",
            "Epoch [3/50], Step [140/815], Loss: 5.2128\n",
            "Epoch [3/50], Step [160/815], Loss: 4.9621\n",
            "Epoch [3/50], Step [180/815], Loss: 5.2182\n",
            "Epoch [3/50], Step [200/815], Loss: 4.9814\n",
            "Epoch [3/50], Step [220/815], Loss: 5.0608\n",
            "Epoch [3/50], Step [240/815], Loss: 5.2671\n",
            "Epoch [3/50], Step [260/815], Loss: 4.9522\n",
            "Epoch [3/50], Step [280/815], Loss: 4.8792\n",
            "Epoch [3/50], Step [300/815], Loss: 5.0619\n",
            "Epoch [3/50], Step [320/815], Loss: 5.1436\n",
            "Epoch [3/50], Step [340/815], Loss: 4.9954\n",
            "Epoch [3/50], Step [360/815], Loss: 5.0549\n",
            "Epoch [3/50], Step [380/815], Loss: 4.8751\n",
            "Epoch [3/50], Step [400/815], Loss: 5.0416\n",
            "Epoch [3/50], Step [420/815], Loss: 5.1934\n",
            "Epoch [3/50], Step [440/815], Loss: 5.0462\n",
            "Epoch [3/50], Step [460/815], Loss: 5.2970\n",
            "Epoch [3/50], Step [480/815], Loss: 5.0206\n",
            "Epoch [3/50], Step [500/815], Loss: 5.0716\n",
            "Epoch [3/50], Step [520/815], Loss: 5.2894\n",
            "Epoch [3/50], Step [540/815], Loss: 5.2147\n",
            "Epoch [3/50], Step [560/815], Loss: 5.1410\n",
            "Epoch [3/50], Step [580/815], Loss: 5.1988\n",
            "Epoch [3/50], Step [600/815], Loss: 5.1006\n",
            "Epoch [3/50], Step [620/815], Loss: 5.2337\n",
            "Epoch [3/50], Step [640/815], Loss: 5.2085\n",
            "Epoch [3/50], Step [660/815], Loss: 4.9980\n",
            "Epoch [3/50], Step [680/815], Loss: 5.1856\n",
            "Epoch [3/50], Step [700/815], Loss: 4.9609\n",
            "Epoch [3/50], Step [720/815], Loss: 4.9150\n",
            "Epoch [3/50], Step [740/815], Loss: 5.0459\n",
            "Epoch [3/50], Step [760/815], Loss: 4.9294\n",
            "Epoch [3/50], Step [780/815], Loss: 4.8938\n",
            "Epoch [3/50], Step [800/815], Loss: 5.2513\n",
            "\n",
            "train-loss: 5.2056, train-acc: 2.8364\n",
            "validation loss: 5.1556, validation acc: 2.7235\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 4\n",
            "\n",
            "Epoch [4/50], Step [0/815], Loss: 5.1591\n",
            "Epoch [4/50], Step [20/815], Loss: 5.2430\n",
            "Epoch [4/50], Step [40/815], Loss: 4.6009\n",
            "Epoch [4/50], Step [60/815], Loss: 5.1170\n",
            "Epoch [4/50], Step [80/815], Loss: 5.0798\n",
            "Epoch [4/50], Step [100/815], Loss: 5.2906\n",
            "Epoch [4/50], Step [120/815], Loss: 5.2284\n",
            "Epoch [4/50], Step [140/815], Loss: 5.0300\n",
            "Epoch [4/50], Step [160/815], Loss: 4.8653\n",
            "Epoch [4/50], Step [180/815], Loss: 5.1085\n",
            "Epoch [4/50], Step [200/815], Loss: 5.1709\n",
            "Epoch [4/50], Step [220/815], Loss: 5.0051\n",
            "Epoch [4/50], Step [240/815], Loss: 5.1811\n",
            "Epoch [4/50], Step [260/815], Loss: 5.1109\n",
            "Epoch [4/50], Step [280/815], Loss: 5.0091\n",
            "Epoch [4/50], Step [300/815], Loss: 5.0814\n",
            "Epoch [4/50], Step [320/815], Loss: 4.8888\n",
            "Epoch [4/50], Step [340/815], Loss: 4.8998\n",
            "Epoch [4/50], Step [360/815], Loss: 5.2088\n",
            "Epoch [4/50], Step [380/815], Loss: 5.1681\n",
            "Epoch [4/50], Step [400/815], Loss: 5.0896\n",
            "Epoch [4/50], Step [420/815], Loss: 5.0262\n",
            "Epoch [4/50], Step [440/815], Loss: 4.8632\n",
            "Epoch [4/50], Step [460/815], Loss: 4.8906\n",
            "Epoch [4/50], Step [480/815], Loss: 5.2087\n",
            "Epoch [4/50], Step [500/815], Loss: 4.9339\n",
            "Epoch [4/50], Step [520/815], Loss: 4.8052\n",
            "Epoch [4/50], Step [540/815], Loss: 5.0216\n",
            "Epoch [4/50], Step [560/815], Loss: 5.1753\n",
            "Epoch [4/50], Step [580/815], Loss: 5.3535\n",
            "Epoch [4/50], Step [600/815], Loss: 5.0657\n",
            "Epoch [4/50], Step [620/815], Loss: 5.1829\n",
            "Epoch [4/50], Step [640/815], Loss: 4.8671\n",
            "Epoch [4/50], Step [660/815], Loss: 5.1908\n",
            "Epoch [4/50], Step [680/815], Loss: 5.3076\n",
            "Epoch [4/50], Step [700/815], Loss: 5.0906\n",
            "Epoch [4/50], Step [720/815], Loss: 4.9134\n",
            "Epoch [4/50], Step [740/815], Loss: 4.8222\n",
            "Epoch [4/50], Step [760/815], Loss: 4.9567\n",
            "Epoch [4/50], Step [780/815], Loss: 5.0169\n",
            "Epoch [4/50], Step [800/815], Loss: 5.1275\n",
            "\n",
            "train-loss: 5.1632, train-acc: 4.0889\n",
            "validation loss: 5.1181, validation acc: 4.0667\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 5\n",
            "\n",
            "Epoch [5/50], Step [0/815], Loss: 4.8347\n",
            "Epoch [5/50], Step [20/815], Loss: 4.9156\n",
            "Epoch [5/50], Step [40/815], Loss: 4.9919\n",
            "Epoch [5/50], Step [60/815], Loss: 5.0299\n",
            "Epoch [5/50], Step [80/815], Loss: 4.9471\n",
            "Epoch [5/50], Step [100/815], Loss: 5.0258\n",
            "Epoch [5/50], Step [120/815], Loss: 4.8593\n",
            "Epoch [5/50], Step [140/815], Loss: 4.8951\n",
            "Epoch [5/50], Step [160/815], Loss: 5.0640\n",
            "Epoch [5/50], Step [180/815], Loss: 5.2541\n",
            "Epoch [5/50], Step [200/815], Loss: 4.8122\n",
            "Epoch [5/50], Step [220/815], Loss: 4.8538\n",
            "Epoch [5/50], Step [240/815], Loss: 4.6897\n",
            "Epoch [5/50], Step [260/815], Loss: 5.1329\n",
            "Epoch [5/50], Step [280/815], Loss: 4.8327\n",
            "Epoch [5/50], Step [300/815], Loss: 4.9282\n",
            "Epoch [5/50], Step [320/815], Loss: 4.9915\n",
            "Epoch [5/50], Step [340/815], Loss: 5.0620\n",
            "Epoch [5/50], Step [360/815], Loss: 4.9504\n",
            "Epoch [5/50], Step [380/815], Loss: 4.9483\n",
            "Epoch [5/50], Step [400/815], Loss: 5.0303\n",
            "Epoch [5/50], Step [420/815], Loss: 5.0576\n",
            "Epoch [5/50], Step [440/815], Loss: 5.0617\n",
            "Epoch [5/50], Step [460/815], Loss: 4.6794\n",
            "Epoch [5/50], Step [480/815], Loss: 4.7169\n",
            "Epoch [5/50], Step [500/815], Loss: 4.9314\n",
            "Epoch [5/50], Step [520/815], Loss: 4.7708\n",
            "Epoch [5/50], Step [540/815], Loss: 5.0863\n",
            "Epoch [5/50], Step [560/815], Loss: 4.5484\n",
            "Epoch [5/50], Step [580/815], Loss: 4.5923\n",
            "Epoch [5/50], Step [600/815], Loss: 4.6293\n",
            "Epoch [5/50], Step [620/815], Loss: 4.9515\n",
            "Epoch [5/50], Step [640/815], Loss: 4.8283\n",
            "Epoch [5/50], Step [660/815], Loss: 5.1058\n",
            "Epoch [5/50], Step [680/815], Loss: 4.5945\n",
            "Epoch [5/50], Step [700/815], Loss: 4.9422\n",
            "Epoch [5/50], Step [720/815], Loss: 5.0049\n",
            "Epoch [5/50], Step [740/815], Loss: 5.0885\n",
            "Epoch [5/50], Step [760/815], Loss: 4.8302\n",
            "Epoch [5/50], Step [780/815], Loss: 4.7084\n",
            "Epoch [5/50], Step [800/815], Loss: 4.9506\n",
            "\n",
            "train-loss: 5.1218, train-acc: 5.6361\n",
            "validation loss: 5.0807, validation acc: 5.3725\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 6\n",
            "\n",
            "Epoch [6/50], Step [0/815], Loss: 4.7817\n",
            "Epoch [6/50], Step [20/815], Loss: 4.7945\n",
            "Epoch [6/50], Step [40/815], Loss: 4.7457\n",
            "Epoch [6/50], Step [60/815], Loss: 5.0623\n",
            "Epoch [6/50], Step [80/815], Loss: 5.0795\n",
            "Epoch [6/50], Step [100/815], Loss: 4.8301\n",
            "Epoch [6/50], Step [120/815], Loss: 5.0418\n",
            "Epoch [6/50], Step [140/815], Loss: 4.9628\n",
            "Epoch [6/50], Step [160/815], Loss: 4.9484\n",
            "Epoch [6/50], Step [180/815], Loss: 5.2472\n",
            "Epoch [6/50], Step [200/815], Loss: 5.0322\n",
            "Epoch [6/50], Step [220/815], Loss: 4.8817\n",
            "Epoch [6/50], Step [240/815], Loss: 4.9398\n",
            "Epoch [6/50], Step [260/815], Loss: 5.1239\n",
            "Epoch [6/50], Step [280/815], Loss: 4.7471\n",
            "Epoch [6/50], Step [300/815], Loss: 4.8931\n",
            "Epoch [6/50], Step [320/815], Loss: 5.1230\n",
            "Epoch [6/50], Step [340/815], Loss: 4.9851\n",
            "Epoch [6/50], Step [360/815], Loss: 4.7122\n",
            "Epoch [6/50], Step [380/815], Loss: 4.8333\n",
            "Epoch [6/50], Step [400/815], Loss: 4.7462\n",
            "Epoch [6/50], Step [420/815], Loss: 4.8212\n",
            "Epoch [6/50], Step [440/815], Loss: 4.7616\n",
            "Epoch [6/50], Step [460/815], Loss: 4.5561\n",
            "Epoch [6/50], Step [480/815], Loss: 4.8786\n",
            "Epoch [6/50], Step [500/815], Loss: 5.1363\n",
            "Epoch [6/50], Step [520/815], Loss: 4.7299\n",
            "Epoch [6/50], Step [540/815], Loss: 4.8230\n",
            "Epoch [6/50], Step [560/815], Loss: 5.0634\n",
            "Epoch [6/50], Step [580/815], Loss: 5.1260\n",
            "Epoch [6/50], Step [600/815], Loss: 4.9633\n",
            "Epoch [6/50], Step [620/815], Loss: 4.8181\n",
            "Epoch [6/50], Step [640/815], Loss: 5.1004\n",
            "Epoch [6/50], Step [660/815], Loss: 4.9064\n",
            "Epoch [6/50], Step [680/815], Loss: 5.0641\n",
            "Epoch [6/50], Step [700/815], Loss: 4.8740\n",
            "Epoch [6/50], Step [720/815], Loss: 5.0930\n",
            "Epoch [6/50], Step [740/815], Loss: 4.5799\n",
            "Epoch [6/50], Step [760/815], Loss: 4.9426\n",
            "Epoch [6/50], Step [780/815], Loss: 4.9844\n",
            "Epoch [6/50], Step [800/815], Loss: 5.0260\n",
            "\n",
            "train-loss: 5.0814, train-acc: 6.9745\n",
            "validation loss: 5.0443, validation acc: 6.3425\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 7\n",
            "\n",
            "Epoch [7/50], Step [0/815], Loss: 4.7863\n",
            "Epoch [7/50], Step [20/815], Loss: 4.7069\n",
            "Epoch [7/50], Step [40/815], Loss: 5.0096\n",
            "Epoch [7/50], Step [60/815], Loss: 4.5236\n",
            "Epoch [7/50], Step [80/815], Loss: 4.7184\n",
            "Epoch [7/50], Step [100/815], Loss: 4.7524\n",
            "Epoch [7/50], Step [120/815], Loss: 4.7016\n",
            "Epoch [7/50], Step [140/815], Loss: 4.9355\n",
            "Epoch [7/50], Step [160/815], Loss: 4.8392\n",
            "Epoch [7/50], Step [180/815], Loss: 4.8682\n",
            "Epoch [7/50], Step [200/815], Loss: 4.9509\n",
            "Epoch [7/50], Step [220/815], Loss: 4.9779\n",
            "Epoch [7/50], Step [240/815], Loss: 4.7035\n",
            "Epoch [7/50], Step [260/815], Loss: 4.7313\n",
            "Epoch [7/50], Step [280/815], Loss: 5.0237\n",
            "Epoch [7/50], Step [300/815], Loss: 4.8555\n",
            "Epoch [7/50], Step [320/815], Loss: 4.8528\n",
            "Epoch [7/50], Step [340/815], Loss: 5.0867\n",
            "Epoch [7/50], Step [360/815], Loss: 4.7062\n",
            "Epoch [7/50], Step [380/815], Loss: 4.8595\n",
            "Epoch [7/50], Step [400/815], Loss: 4.6136\n",
            "Epoch [7/50], Step [420/815], Loss: 4.7875\n",
            "Epoch [7/50], Step [440/815], Loss: 4.7897\n",
            "Epoch [7/50], Step [460/815], Loss: 4.6320\n",
            "Epoch [7/50], Step [480/815], Loss: 4.5862\n",
            "Epoch [7/50], Step [500/815], Loss: 4.7116\n",
            "Epoch [7/50], Step [520/815], Loss: 4.6000\n",
            "Epoch [7/50], Step [540/815], Loss: 5.0649\n",
            "Epoch [7/50], Step [560/815], Loss: 4.9748\n",
            "Epoch [7/50], Step [580/815], Loss: 4.8788\n",
            "Epoch [7/50], Step [600/815], Loss: 4.8518\n",
            "Epoch [7/50], Step [620/815], Loss: 4.5607\n",
            "Epoch [7/50], Step [640/815], Loss: 5.2189\n",
            "Epoch [7/50], Step [660/815], Loss: 4.6596\n",
            "Epoch [7/50], Step [680/815], Loss: 4.5279\n",
            "Epoch [7/50], Step [700/815], Loss: 4.6561\n",
            "Epoch [7/50], Step [720/815], Loss: 4.9242\n",
            "Epoch [7/50], Step [740/815], Loss: 4.8819\n",
            "Epoch [7/50], Step [760/815], Loss: 5.0802\n",
            "Epoch [7/50], Step [780/815], Loss: 4.9285\n",
            "Epoch [7/50], Step [800/815], Loss: 4.7290\n",
            "\n",
            "train-loss: 5.0429, train-acc: 8.1655\n",
            "validation loss: 5.0084, validation acc: 7.7602\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 8\n",
            "\n",
            "Epoch [8/50], Step [0/815], Loss: 4.8098\n",
            "Epoch [8/50], Step [20/815], Loss: 4.5682\n",
            "Epoch [8/50], Step [40/815], Loss: 4.6653\n",
            "Epoch [8/50], Step [60/815], Loss: 4.5261\n",
            "Epoch [8/50], Step [80/815], Loss: 4.8571\n",
            "Epoch [8/50], Step [100/815], Loss: 5.0624\n",
            "Epoch [8/50], Step [120/815], Loss: 4.6254\n",
            "Epoch [8/50], Step [140/815], Loss: 4.8280\n",
            "Epoch [8/50], Step [160/815], Loss: 4.9194\n",
            "Epoch [8/50], Step [180/815], Loss: 4.7936\n",
            "Epoch [8/50], Step [200/815], Loss: 4.7463\n",
            "Epoch [8/50], Step [220/815], Loss: 4.8508\n",
            "Epoch [8/50], Step [240/815], Loss: 4.8635\n",
            "Epoch [8/50], Step [260/815], Loss: 4.8642\n",
            "Epoch [8/50], Step [280/815], Loss: 4.7940\n",
            "Epoch [8/50], Step [300/815], Loss: 4.8042\n",
            "Epoch [8/50], Step [320/815], Loss: 4.8300\n",
            "Epoch [8/50], Step [340/815], Loss: 4.7082\n",
            "Epoch [8/50], Step [360/815], Loss: 4.6076\n",
            "Epoch [8/50], Step [380/815], Loss: 4.8597\n",
            "Epoch [8/50], Step [400/815], Loss: 4.8519\n",
            "Epoch [8/50], Step [420/815], Loss: 4.7090\n",
            "Epoch [8/50], Step [440/815], Loss: 4.3728\n",
            "Epoch [8/50], Step [460/815], Loss: 4.9913\n",
            "Epoch [8/50], Step [480/815], Loss: 4.5953\n",
            "Epoch [8/50], Step [500/815], Loss: 4.8674\n",
            "Epoch [8/50], Step [520/815], Loss: 4.6726\n",
            "Epoch [8/50], Step [540/815], Loss: 4.7846\n",
            "Epoch [8/50], Step [560/815], Loss: 4.8534\n",
            "Epoch [8/50], Step [580/815], Loss: 4.6262\n",
            "Epoch [8/50], Step [600/815], Loss: 4.5732\n",
            "Epoch [8/50], Step [620/815], Loss: 4.6117\n",
            "Epoch [8/50], Step [640/815], Loss: 4.7685\n",
            "Epoch [8/50], Step [660/815], Loss: 4.7832\n",
            "Epoch [8/50], Step [680/815], Loss: 4.6781\n",
            "Epoch [8/50], Step [700/815], Loss: 4.7973\n",
            "Epoch [8/50], Step [720/815], Loss: 4.6778\n",
            "Epoch [8/50], Step [740/815], Loss: 4.9093\n",
            "Epoch [8/50], Step [760/815], Loss: 4.4904\n",
            "Epoch [8/50], Step [780/815], Loss: 5.1766\n",
            "Epoch [8/50], Step [800/815], Loss: 4.7432\n",
            "\n",
            "train-loss: 5.0062, train-acc: 9.6022\n",
            "validation loss: 4.9750, validation acc: 8.6556\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 9\n",
            "\n",
            "Epoch [9/50], Step [0/815], Loss: 4.6227\n",
            "Epoch [9/50], Step [20/815], Loss: 4.6944\n",
            "Epoch [9/50], Step [40/815], Loss: 4.7865\n",
            "Epoch [9/50], Step [60/815], Loss: 4.7132\n",
            "Epoch [9/50], Step [80/815], Loss: 4.7811\n",
            "Epoch [9/50], Step [100/815], Loss: 4.3357\n",
            "Epoch [9/50], Step [120/815], Loss: 4.6490\n",
            "Epoch [9/50], Step [140/815], Loss: 4.6871\n",
            "Epoch [9/50], Step [160/815], Loss: 4.7772\n",
            "Epoch [9/50], Step [180/815], Loss: 4.5358\n",
            "Epoch [9/50], Step [200/815], Loss: 4.7119\n",
            "Epoch [9/50], Step [220/815], Loss: 4.5983\n",
            "Epoch [9/50], Step [240/815], Loss: 4.5857\n",
            "Epoch [9/50], Step [260/815], Loss: 4.5582\n",
            "Epoch [9/50], Step [280/815], Loss: 4.3940\n",
            "Epoch [9/50], Step [300/815], Loss: 4.5439\n",
            "Epoch [9/50], Step [320/815], Loss: 4.9320\n",
            "Epoch [9/50], Step [340/815], Loss: 4.6401\n",
            "Epoch [9/50], Step [360/815], Loss: 4.7242\n",
            "Epoch [9/50], Step [380/815], Loss: 4.6592\n",
            "Epoch [9/50], Step [400/815], Loss: 4.7301\n",
            "Epoch [9/50], Step [420/815], Loss: 4.4180\n",
            "Epoch [9/50], Step [440/815], Loss: 4.7603\n",
            "Epoch [9/50], Step [460/815], Loss: 4.6421\n",
            "Epoch [9/50], Step [480/815], Loss: 4.3918\n",
            "Epoch [9/50], Step [500/815], Loss: 4.6661\n",
            "Epoch [9/50], Step [520/815], Loss: 4.6921\n",
            "Epoch [9/50], Step [540/815], Loss: 4.7924\n",
            "Epoch [9/50], Step [560/815], Loss: 4.4467\n",
            "Epoch [9/50], Step [580/815], Loss: 4.6431\n",
            "Epoch [9/50], Step [600/815], Loss: 4.5481\n",
            "Epoch [9/50], Step [620/815], Loss: 4.6061\n",
            "Epoch [9/50], Step [640/815], Loss: 4.7119\n",
            "Epoch [9/50], Step [660/815], Loss: 4.6228\n",
            "Epoch [9/50], Step [680/815], Loss: 4.8294\n",
            "Epoch [9/50], Step [700/815], Loss: 4.7168\n",
            "Epoch [9/50], Step [720/815], Loss: 4.4108\n",
            "Epoch [9/50], Step [740/815], Loss: 4.4696\n",
            "Epoch [9/50], Step [760/815], Loss: 4.8925\n",
            "Epoch [9/50], Step [780/815], Loss: 4.7428\n",
            "Epoch [9/50], Step [800/815], Loss: 4.7334\n",
            "\n",
            "train-loss: 4.9697, train-acc: 11.5054\n",
            "validation loss: 4.9412, validation acc: 9.7749\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 10\n",
            "\n",
            "Epoch [10/50], Step [0/815], Loss: 4.7492\n",
            "Epoch [10/50], Step [20/815], Loss: 4.5349\n",
            "Epoch [10/50], Step [40/815], Loss: 4.8237\n",
            "Epoch [10/50], Step [60/815], Loss: 4.5660\n",
            "Epoch [10/50], Step [80/815], Loss: 4.6590\n",
            "Epoch [10/50], Step [100/815], Loss: 4.6250\n",
            "Epoch [10/50], Step [120/815], Loss: 4.7668\n",
            "Epoch [10/50], Step [140/815], Loss: 4.8025\n",
            "Epoch [10/50], Step [160/815], Loss: 4.7524\n",
            "Epoch [10/50], Step [180/815], Loss: 4.6796\n",
            "Epoch [10/50], Step [200/815], Loss: 4.4510\n",
            "Epoch [10/50], Step [220/815], Loss: 4.1591\n",
            "Epoch [10/50], Step [240/815], Loss: 4.4010\n",
            "Epoch [10/50], Step [260/815], Loss: 4.5271\n",
            "Epoch [10/50], Step [280/815], Loss: 4.5047\n",
            "Epoch [10/50], Step [300/815], Loss: 4.5766\n",
            "Epoch [10/50], Step [320/815], Loss: 4.2845\n",
            "Epoch [10/50], Step [340/815], Loss: 4.5791\n",
            "Epoch [10/50], Step [360/815], Loss: 4.7260\n",
            "Epoch [10/50], Step [380/815], Loss: 4.7330\n",
            "Epoch [10/50], Step [400/815], Loss: 4.6339\n",
            "Epoch [10/50], Step [420/815], Loss: 4.5345\n",
            "Epoch [10/50], Step [440/815], Loss: 4.5628\n",
            "Epoch [10/50], Step [460/815], Loss: 4.4783\n",
            "Epoch [10/50], Step [480/815], Loss: 4.4751\n",
            "Epoch [10/50], Step [500/815], Loss: 4.7810\n",
            "Epoch [10/50], Step [520/815], Loss: 4.4873\n",
            "Epoch [10/50], Step [540/815], Loss: 4.3933\n",
            "Epoch [10/50], Step [560/815], Loss: 4.6253\n",
            "Epoch [10/50], Step [580/815], Loss: 4.7965\n",
            "Epoch [10/50], Step [600/815], Loss: 4.6564\n",
            "Epoch [10/50], Step [620/815], Loss: 4.5248\n",
            "Epoch [10/50], Step [640/815], Loss: 4.6295\n",
            "Epoch [10/50], Step [660/815], Loss: 4.5203\n",
            "Epoch [10/50], Step [680/815], Loss: 4.5132\n",
            "Epoch [10/50], Step [700/815], Loss: 4.4610\n",
            "Epoch [10/50], Step [720/815], Loss: 4.9357\n",
            "Epoch [10/50], Step [740/815], Loss: 4.5463\n",
            "Epoch [10/50], Step [760/815], Loss: 4.5256\n",
            "Epoch [10/50], Step [780/815], Loss: 4.7487\n",
            "Epoch [10/50], Step [800/815], Loss: 4.5556\n",
            "\n",
            "train-loss: 4.9341, train-acc: 12.8315\n",
            "validation loss: 4.9093, validation acc: 10.3967\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 11\n",
            "\n",
            "Epoch [11/50], Step [0/815], Loss: 4.6044\n",
            "Epoch [11/50], Step [20/815], Loss: 4.3635\n",
            "Epoch [11/50], Step [40/815], Loss: 4.3954\n",
            "Epoch [11/50], Step [60/815], Loss: 4.6808\n",
            "Epoch [11/50], Step [80/815], Loss: 4.6653\n",
            "Epoch [11/50], Step [100/815], Loss: 4.7368\n",
            "Epoch [11/50], Step [120/815], Loss: 4.7869\n",
            "Epoch [11/50], Step [140/815], Loss: 4.3745\n",
            "Epoch [11/50], Step [160/815], Loss: 4.3440\n",
            "Epoch [11/50], Step [180/815], Loss: 4.3092\n",
            "Epoch [11/50], Step [200/815], Loss: 4.6838\n",
            "Epoch [11/50], Step [220/815], Loss: 4.6402\n",
            "Epoch [11/50], Step [240/815], Loss: 4.6955\n",
            "Epoch [11/50], Step [260/815], Loss: 4.6004\n",
            "Epoch [11/50], Step [280/815], Loss: 4.4137\n",
            "Epoch [11/50], Step [300/815], Loss: 4.6445\n",
            "Epoch [11/50], Step [320/815], Loss: 4.4450\n",
            "Epoch [11/50], Step [340/815], Loss: 4.4350\n",
            "Epoch [11/50], Step [360/815], Loss: 4.4430\n",
            "Epoch [11/50], Step [380/815], Loss: 4.5737\n",
            "Epoch [11/50], Step [400/815], Loss: 4.3680\n",
            "Epoch [11/50], Step [420/815], Loss: 4.8573\n",
            "Epoch [11/50], Step [440/815], Loss: 4.6363\n",
            "Epoch [11/50], Step [460/815], Loss: 4.3008\n",
            "Epoch [11/50], Step [480/815], Loss: 4.4338\n",
            "Epoch [11/50], Step [500/815], Loss: 4.2500\n",
            "Epoch [11/50], Step [520/815], Loss: 4.3524\n",
            "Epoch [11/50], Step [540/815], Loss: 4.3868\n",
            "Epoch [11/50], Step [560/815], Loss: 4.4372\n",
            "Epoch [11/50], Step [580/815], Loss: 4.7671\n",
            "Epoch [11/50], Step [600/815], Loss: 4.2899\n",
            "Epoch [11/50], Step [620/815], Loss: 4.4860\n",
            "Epoch [11/50], Step [640/815], Loss: 4.2900\n",
            "Epoch [11/50], Step [660/815], Loss: 4.5155\n",
            "Epoch [11/50], Step [680/815], Loss: 4.5179\n",
            "Epoch [11/50], Step [700/815], Loss: 4.3872\n",
            "Epoch [11/50], Step [720/815], Loss: 4.4998\n",
            "Epoch [11/50], Step [740/815], Loss: 4.4727\n",
            "Epoch [11/50], Step [760/815], Loss: 4.3218\n",
            "Epoch [11/50], Step [780/815], Loss: 4.5639\n",
            "Epoch [11/50], Step [800/815], Loss: 4.5346\n",
            "\n",
            "train-loss: 4.8998, train-acc: 13.9244\n",
            "validation loss: 4.8780, validation acc: 11.6528\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 12\n",
            "\n",
            "Epoch [12/50], Step [0/815], Loss: 4.8059\n",
            "Epoch [12/50], Step [20/815], Loss: 4.4962\n",
            "Epoch [12/50], Step [40/815], Loss: 4.6728\n",
            "Epoch [12/50], Step [60/815], Loss: 4.4201\n",
            "Epoch [12/50], Step [80/815], Loss: 4.4684\n",
            "Epoch [12/50], Step [100/815], Loss: 4.6010\n",
            "Epoch [12/50], Step [120/815], Loss: 4.9887\n",
            "Epoch [12/50], Step [140/815], Loss: 4.6505\n",
            "Epoch [12/50], Step [160/815], Loss: 4.4615\n",
            "Epoch [12/50], Step [180/815], Loss: 4.5244\n",
            "Epoch [12/50], Step [200/815], Loss: 4.4789\n",
            "Epoch [12/50], Step [220/815], Loss: 4.7604\n",
            "Epoch [12/50], Step [240/815], Loss: 4.9955\n",
            "Epoch [12/50], Step [260/815], Loss: 4.4837\n",
            "Epoch [12/50], Step [280/815], Loss: 4.1998\n",
            "Epoch [12/50], Step [300/815], Loss: 4.6150\n",
            "Epoch [12/50], Step [320/815], Loss: 4.2892\n",
            "Epoch [12/50], Step [340/815], Loss: 4.3789\n",
            "Epoch [12/50], Step [360/815], Loss: 4.6533\n",
            "Epoch [12/50], Step [380/815], Loss: 4.8095\n",
            "Epoch [12/50], Step [400/815], Loss: 4.5708\n",
            "Epoch [12/50], Step [420/815], Loss: 4.4584\n",
            "Epoch [12/50], Step [440/815], Loss: 4.9738\n",
            "Epoch [12/50], Step [460/815], Loss: 4.1955\n",
            "Epoch [12/50], Step [480/815], Loss: 4.5948\n",
            "Epoch [12/50], Step [500/815], Loss: 4.3536\n",
            "Epoch [12/50], Step [520/815], Loss: 4.8230\n",
            "Epoch [12/50], Step [540/815], Loss: 4.6852\n",
            "Epoch [12/50], Step [560/815], Loss: 4.5885\n",
            "Epoch [12/50], Step [580/815], Loss: 4.4570\n",
            "Epoch [12/50], Step [600/815], Loss: 4.5211\n",
            "Epoch [12/50], Step [620/815], Loss: 4.4860\n",
            "Epoch [12/50], Step [640/815], Loss: 4.4148\n",
            "Epoch [12/50], Step [660/815], Loss: 4.2754\n",
            "Epoch [12/50], Step [680/815], Loss: 4.3466\n",
            "Epoch [12/50], Step [700/815], Loss: 4.2324\n",
            "Epoch [12/50], Step [720/815], Loss: 4.8417\n",
            "Epoch [12/50], Step [740/815], Loss: 4.6247\n",
            "Epoch [12/50], Step [760/815], Loss: 4.8281\n",
            "Epoch [12/50], Step [780/815], Loss: 4.3045\n",
            "Epoch [12/50], Step [800/815], Loss: 4.3506\n",
            "\n",
            "train-loss: 4.8660, train-acc: 15.2382\n",
            "validation loss: 4.8473, validation acc: 12.7720\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 13\n",
            "\n",
            "Epoch [13/50], Step [0/815], Loss: 4.0881\n",
            "Epoch [13/50], Step [20/815], Loss: 4.5782\n",
            "Epoch [13/50], Step [40/815], Loss: 4.2925\n",
            "Epoch [13/50], Step [60/815], Loss: 4.5936\n",
            "Epoch [13/50], Step [80/815], Loss: 4.3868\n",
            "Epoch [13/50], Step [100/815], Loss: 4.6144\n",
            "Epoch [13/50], Step [120/815], Loss: 4.5021\n",
            "Epoch [13/50], Step [140/815], Loss: 3.9522\n",
            "Epoch [13/50], Step [160/815], Loss: 4.4565\n",
            "Epoch [13/50], Step [180/815], Loss: 4.3890\n",
            "Epoch [13/50], Step [200/815], Loss: 4.2975\n",
            "Epoch [13/50], Step [220/815], Loss: 4.8847\n",
            "Epoch [13/50], Step [240/815], Loss: 4.3744\n",
            "Epoch [13/50], Step [260/815], Loss: 4.0265\n",
            "Epoch [13/50], Step [280/815], Loss: 4.7111\n",
            "Epoch [13/50], Step [300/815], Loss: 4.1152\n",
            "Epoch [13/50], Step [320/815], Loss: 4.6184\n",
            "Epoch [13/50], Step [340/815], Loss: 4.1445\n",
            "Epoch [13/50], Step [360/815], Loss: 4.5597\n",
            "Epoch [13/50], Step [380/815], Loss: 4.4708\n",
            "Epoch [13/50], Step [400/815], Loss: 4.2384\n",
            "Epoch [13/50], Step [420/815], Loss: 4.1734\n",
            "Epoch [13/50], Step [440/815], Loss: 4.3965\n",
            "Epoch [13/50], Step [460/815], Loss: 4.3738\n",
            "Epoch [13/50], Step [480/815], Loss: 4.7050\n",
            "Epoch [13/50], Step [500/815], Loss: 4.4859\n",
            "Epoch [13/50], Step [520/815], Loss: 4.4846\n",
            "Epoch [13/50], Step [540/815], Loss: 4.5901\n",
            "Epoch [13/50], Step [560/815], Loss: 4.5706\n",
            "Epoch [13/50], Step [580/815], Loss: 4.6441\n",
            "Epoch [13/50], Step [600/815], Loss: 4.3320\n",
            "Epoch [13/50], Step [620/815], Loss: 4.5901\n",
            "Epoch [13/50], Step [640/815], Loss: 4.5079\n",
            "Epoch [13/50], Step [660/815], Loss: 4.1866\n",
            "Epoch [13/50], Step [680/815], Loss: 4.6685\n",
            "Epoch [13/50], Step [700/815], Loss: 4.1182\n",
            "Epoch [13/50], Step [720/815], Loss: 4.2610\n",
            "Epoch [13/50], Step [740/815], Loss: 4.1529\n",
            "Epoch [13/50], Step [760/815], Loss: 4.7260\n",
            "Epoch [13/50], Step [780/815], Loss: 4.7993\n",
            "Epoch [13/50], Step [800/815], Loss: 4.5186\n",
            "\n",
            "train-loss: 4.8328, train-acc: 17.0432\n",
            "validation loss: 4.8184, validation acc: 13.5804\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 14\n",
            "\n",
            "Epoch [14/50], Step [0/815], Loss: 4.3948\n",
            "Epoch [14/50], Step [20/815], Loss: 4.5932\n",
            "Epoch [14/50], Step [40/815], Loss: 4.4940\n",
            "Epoch [14/50], Step [60/815], Loss: 4.1358\n",
            "Epoch [14/50], Step [80/815], Loss: 4.5032\n",
            "Epoch [14/50], Step [100/815], Loss: 4.3349\n",
            "Epoch [14/50], Step [120/815], Loss: 3.9217\n",
            "Epoch [14/50], Step [140/815], Loss: 4.3875\n",
            "Epoch [14/50], Step [160/815], Loss: 4.6515\n",
            "Epoch [14/50], Step [180/815], Loss: 4.2259\n",
            "Epoch [14/50], Step [200/815], Loss: 4.3658\n",
            "Epoch [14/50], Step [220/815], Loss: 4.6877\n",
            "Epoch [14/50], Step [240/815], Loss: 4.5003\n",
            "Epoch [14/50], Step [260/815], Loss: 4.6344\n",
            "Epoch [14/50], Step [280/815], Loss: 4.5206\n",
            "Epoch [14/50], Step [300/815], Loss: 4.2097\n",
            "Epoch [14/50], Step [320/815], Loss: 4.0458\n",
            "Epoch [14/50], Step [340/815], Loss: 4.1978\n",
            "Epoch [14/50], Step [360/815], Loss: 4.4873\n",
            "Epoch [14/50], Step [380/815], Loss: 3.9838\n",
            "Epoch [14/50], Step [400/815], Loss: 3.9552\n",
            "Epoch [14/50], Step [420/815], Loss: 4.3483\n",
            "Epoch [14/50], Step [440/815], Loss: 4.5105\n",
            "Epoch [14/50], Step [460/815], Loss: 4.0983\n",
            "Epoch [14/50], Step [480/815], Loss: 4.2700\n",
            "Epoch [14/50], Step [500/815], Loss: 4.5275\n",
            "Epoch [14/50], Step [520/815], Loss: 4.0424\n",
            "Epoch [14/50], Step [540/815], Loss: 4.5000\n",
            "Epoch [14/50], Step [560/815], Loss: 4.3644\n",
            "Epoch [14/50], Step [580/815], Loss: 4.4394\n",
            "Epoch [14/50], Step [600/815], Loss: 4.0577\n",
            "Epoch [14/50], Step [620/815], Loss: 4.0983\n",
            "Epoch [14/50], Step [640/815], Loss: 4.2111\n",
            "Epoch [14/50], Step [660/815], Loss: 4.4681\n",
            "Epoch [14/50], Step [680/815], Loss: 4.0892\n",
            "Epoch [14/50], Step [700/815], Loss: 4.1536\n",
            "Epoch [14/50], Step [720/815], Loss: 4.6453\n",
            "Epoch [14/50], Step [740/815], Loss: 4.6101\n",
            "Epoch [14/50], Step [760/815], Loss: 4.2873\n",
            "Epoch [14/50], Step [780/815], Loss: 4.4762\n",
            "Epoch [14/50], Step [800/815], Loss: 4.2023\n",
            "\n",
            "train-loss: 4.8001, train-acc: 18.1606\n",
            "validation loss: 4.7895, validation acc: 14.4136\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 15\n",
            "\n",
            "Epoch [15/50], Step [0/815], Loss: 4.2022\n",
            "Epoch [15/50], Step [20/815], Loss: 4.5885\n",
            "Epoch [15/50], Step [40/815], Loss: 4.5045\n",
            "Epoch [15/50], Step [60/815], Loss: 4.0724\n",
            "Epoch [15/50], Step [80/815], Loss: 4.6408\n",
            "Epoch [15/50], Step [100/815], Loss: 4.8087\n",
            "Epoch [15/50], Step [120/815], Loss: 4.3822\n",
            "Epoch [15/50], Step [140/815], Loss: 4.7689\n",
            "Epoch [15/50], Step [160/815], Loss: 3.8818\n",
            "Epoch [15/50], Step [180/815], Loss: 4.5471\n",
            "Epoch [15/50], Step [200/815], Loss: 4.1220\n",
            "Epoch [15/50], Step [220/815], Loss: 4.8098\n",
            "Epoch [15/50], Step [240/815], Loss: 4.3375\n",
            "Epoch [15/50], Step [260/815], Loss: 4.6908\n",
            "Epoch [15/50], Step [280/815], Loss: 3.9459\n",
            "Epoch [15/50], Step [300/815], Loss: 4.0218\n",
            "Epoch [15/50], Step [320/815], Loss: 4.0055\n",
            "Epoch [15/50], Step [340/815], Loss: 4.4208\n",
            "Epoch [15/50], Step [360/815], Loss: 4.4226\n",
            "Epoch [15/50], Step [380/815], Loss: 4.1060\n",
            "Epoch [15/50], Step [400/815], Loss: 4.4217\n",
            "Epoch [15/50], Step [420/815], Loss: 4.2909\n",
            "Epoch [15/50], Step [440/815], Loss: 4.5554\n",
            "Epoch [15/50], Step [460/815], Loss: 4.4764\n",
            "Epoch [15/50], Step [480/815], Loss: 4.1731\n",
            "Epoch [15/50], Step [500/815], Loss: 4.2425\n",
            "Epoch [15/50], Step [520/815], Loss: 4.2537\n",
            "Epoch [15/50], Step [540/815], Loss: 4.2754\n",
            "Epoch [15/50], Step [560/815], Loss: 4.2020\n",
            "Epoch [15/50], Step [580/815], Loss: 4.5777\n",
            "Epoch [15/50], Step [600/815], Loss: 3.8691\n",
            "Epoch [15/50], Step [620/815], Loss: 4.5470\n",
            "Epoch [15/50], Step [640/815], Loss: 4.4987\n",
            "Epoch [15/50], Step [660/815], Loss: 4.4010\n",
            "Epoch [15/50], Step [680/815], Loss: 4.3560\n",
            "Epoch [15/50], Step [700/815], Loss: 4.4789\n",
            "Epoch [15/50], Step [720/815], Loss: 4.4950\n",
            "Epoch [15/50], Step [740/815], Loss: 3.9627\n",
            "Epoch [15/50], Step [760/815], Loss: 3.7124\n",
            "Epoch [15/50], Step [780/815], Loss: 4.1109\n",
            "Epoch [15/50], Step [800/815], Loss: 4.1424\n",
            "\n",
            "train-loss: 4.7686, train-acc: 19.4131\n",
            "validation loss: 4.7617, validation acc: 14.5380\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 16\n",
            "\n",
            "Epoch [16/50], Step [0/815], Loss: 4.6974\n",
            "Epoch [16/50], Step [20/815], Loss: 4.4943\n",
            "Epoch [16/50], Step [40/815], Loss: 4.0611\n",
            "Epoch [16/50], Step [60/815], Loss: 4.2207\n",
            "Epoch [16/50], Step [80/815], Loss: 4.6143\n",
            "Epoch [16/50], Step [100/815], Loss: 4.5913\n",
            "Epoch [16/50], Step [120/815], Loss: 4.2725\n",
            "Epoch [16/50], Step [140/815], Loss: 4.3938\n",
            "Epoch [16/50], Step [160/815], Loss: 4.3738\n",
            "Epoch [16/50], Step [180/815], Loss: 4.3048\n",
            "Epoch [16/50], Step [200/815], Loss: 4.1331\n",
            "Epoch [16/50], Step [220/815], Loss: 4.0273\n",
            "Epoch [16/50], Step [240/815], Loss: 4.4020\n",
            "Epoch [16/50], Step [260/815], Loss: 4.0163\n",
            "Epoch [16/50], Step [280/815], Loss: 4.1416\n",
            "Epoch [16/50], Step [300/815], Loss: 4.5217\n",
            "Epoch [16/50], Step [320/815], Loss: 4.2449\n",
            "Epoch [16/50], Step [340/815], Loss: 4.5963\n",
            "Epoch [16/50], Step [360/815], Loss: 3.8477\n",
            "Epoch [16/50], Step [380/815], Loss: 4.3063\n",
            "Epoch [16/50], Step [400/815], Loss: 4.6087\n",
            "Epoch [16/50], Step [420/815], Loss: 4.2786\n",
            "Epoch [16/50], Step [440/815], Loss: 4.5081\n",
            "Epoch [16/50], Step [460/815], Loss: 4.2519\n",
            "Epoch [16/50], Step [480/815], Loss: 3.8320\n",
            "Epoch [16/50], Step [500/815], Loss: 4.2185\n",
            "Epoch [16/50], Step [520/815], Loss: 4.2222\n",
            "Epoch [16/50], Step [540/815], Loss: 4.2799\n",
            "Epoch [16/50], Step [560/815], Loss: 4.7215\n",
            "Epoch [16/50], Step [580/815], Loss: 4.6890\n",
            "Epoch [16/50], Step [600/815], Loss: 4.4492\n",
            "Epoch [16/50], Step [620/815], Loss: 4.7463\n",
            "Epoch [16/50], Step [640/815], Loss: 4.1685\n",
            "Epoch [16/50], Step [660/815], Loss: 4.0831\n",
            "Epoch [16/50], Step [680/815], Loss: 3.7175\n",
            "Epoch [16/50], Step [700/815], Loss: 4.5591\n",
            "Epoch [16/50], Step [720/815], Loss: 4.4874\n",
            "Epoch [16/50], Step [740/815], Loss: 4.2415\n",
            "Epoch [16/50], Step [760/815], Loss: 4.0171\n",
            "Epoch [16/50], Step [780/815], Loss: 4.4616\n",
            "Epoch [16/50], Step [800/815], Loss: 3.9583\n",
            "\n",
            "train-loss: 4.7376, train-acc: 20.3954\n",
            "validation loss: 4.7343, validation acc: 15.9557\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 17\n",
            "\n",
            "Epoch [17/50], Step [0/815], Loss: 4.2075\n",
            "Epoch [17/50], Step [20/815], Loss: 3.9945\n",
            "Epoch [17/50], Step [40/815], Loss: 4.1723\n",
            "Epoch [17/50], Step [60/815], Loss: 4.3597\n",
            "Epoch [17/50], Step [80/815], Loss: 4.0279\n",
            "Epoch [17/50], Step [100/815], Loss: 4.6388\n",
            "Epoch [17/50], Step [120/815], Loss: 4.4871\n",
            "Epoch [17/50], Step [140/815], Loss: 4.2126\n",
            "Epoch [17/50], Step [160/815], Loss: 4.0234\n",
            "Epoch [17/50], Step [180/815], Loss: 4.1050\n",
            "Epoch [17/50], Step [200/815], Loss: 4.1461\n",
            "Epoch [17/50], Step [220/815], Loss: 4.4880\n",
            "Epoch [17/50], Step [240/815], Loss: 4.1833\n",
            "Epoch [17/50], Step [260/815], Loss: 3.9194\n",
            "Epoch [17/50], Step [280/815], Loss: 4.2066\n",
            "Epoch [17/50], Step [300/815], Loss: 4.4381\n",
            "Epoch [17/50], Step [320/815], Loss: 4.3525\n",
            "Epoch [17/50], Step [340/815], Loss: 4.2846\n",
            "Epoch [17/50], Step [360/815], Loss: 4.2695\n",
            "Epoch [17/50], Step [380/815], Loss: 4.5954\n",
            "Epoch [17/50], Step [400/815], Loss: 4.0434\n",
            "Epoch [17/50], Step [420/815], Loss: 4.2801\n",
            "Epoch [17/50], Step [440/815], Loss: 3.7516\n",
            "Epoch [17/50], Step [460/815], Loss: 4.3021\n",
            "Epoch [17/50], Step [480/815], Loss: 4.1127\n",
            "Epoch [17/50], Step [500/815], Loss: 3.9305\n",
            "Epoch [17/50], Step [520/815], Loss: 4.3501\n",
            "Epoch [17/50], Step [540/815], Loss: 4.4150\n",
            "Epoch [17/50], Step [560/815], Loss: 3.7115\n",
            "Epoch [17/50], Step [580/815], Loss: 4.3026\n",
            "Epoch [17/50], Step [600/815], Loss: 4.0855\n",
            "Epoch [17/50], Step [620/815], Loss: 4.1092\n",
            "Epoch [17/50], Step [640/815], Loss: 4.0944\n",
            "Epoch [17/50], Step [660/815], Loss: 4.0320\n",
            "Epoch [17/50], Step [680/815], Loss: 4.0242\n",
            "Epoch [17/50], Step [700/815], Loss: 4.4460\n",
            "Epoch [17/50], Step [720/815], Loss: 3.9113\n",
            "Epoch [17/50], Step [740/815], Loss: 3.9101\n",
            "Epoch [17/50], Step [760/815], Loss: 4.3358\n",
            "Epoch [17/50], Step [780/815], Loss: 4.1236\n",
            "Epoch [17/50], Step [800/815], Loss: 4.0824\n",
            "\n",
            "train-loss: 4.7070, train-acc: 22.2250\n",
            "validation loss: 4.7070, validation acc: 16.5278\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 18\n",
            "\n",
            "Epoch [18/50], Step [0/815], Loss: 4.1937\n",
            "Epoch [18/50], Step [20/815], Loss: 3.8805\n",
            "Epoch [18/50], Step [40/815], Loss: 4.5278\n",
            "Epoch [18/50], Step [60/815], Loss: 4.4347\n",
            "Epoch [18/50], Step [80/815], Loss: 4.4792\n",
            "Epoch [18/50], Step [100/815], Loss: 4.4782\n",
            "Epoch [18/50], Step [120/815], Loss: 4.1056\n",
            "Epoch [18/50], Step [140/815], Loss: 3.9524\n",
            "Epoch [18/50], Step [160/815], Loss: 4.5158\n",
            "Epoch [18/50], Step [180/815], Loss: 4.2087\n",
            "Epoch [18/50], Step [200/815], Loss: 4.4090\n",
            "Epoch [18/50], Step [220/815], Loss: 4.5993\n",
            "Epoch [18/50], Step [240/815], Loss: 4.2733\n",
            "Epoch [18/50], Step [260/815], Loss: 4.2025\n",
            "Epoch [18/50], Step [280/815], Loss: 4.0885\n",
            "Epoch [18/50], Step [300/815], Loss: 4.1335\n",
            "Epoch [18/50], Step [320/815], Loss: 4.3066\n",
            "Epoch [18/50], Step [340/815], Loss: 4.1965\n",
            "Epoch [18/50], Step [360/815], Loss: 4.2793\n",
            "Epoch [18/50], Step [380/815], Loss: 4.2547\n",
            "Epoch [18/50], Step [400/815], Loss: 4.2568\n",
            "Epoch [18/50], Step [420/815], Loss: 4.3990\n",
            "Epoch [18/50], Step [440/815], Loss: 4.2346\n",
            "Epoch [18/50], Step [460/815], Loss: 4.2565\n",
            "Epoch [18/50], Step [480/815], Loss: 4.4518\n",
            "Epoch [18/50], Step [500/815], Loss: 3.9592\n",
            "Epoch [18/50], Step [520/815], Loss: 3.8631\n",
            "Epoch [18/50], Step [540/815], Loss: 4.1321\n",
            "Epoch [18/50], Step [560/815], Loss: 4.1263\n",
            "Epoch [18/50], Step [580/815], Loss: 3.9064\n",
            "Epoch [18/50], Step [600/815], Loss: 4.1109\n",
            "Epoch [18/50], Step [620/815], Loss: 4.0079\n",
            "Epoch [18/50], Step [640/815], Loss: 4.6432\n",
            "Epoch [18/50], Step [660/815], Loss: 4.3304\n",
            "Epoch [18/50], Step [680/815], Loss: 4.3217\n",
            "Epoch [18/50], Step [700/815], Loss: 4.3562\n",
            "Epoch [18/50], Step [720/815], Loss: 4.2198\n",
            "Epoch [18/50], Step [740/815], Loss: 4.2155\n",
            "Epoch [18/50], Step [760/815], Loss: 4.4247\n",
            "Epoch [18/50], Step [780/815], Loss: 4.5022\n",
            "Epoch [18/50], Step [800/815], Loss: 3.6839\n",
            "\n",
            "train-loss: 4.6774, train-acc: 23.1827\n",
            "validation loss: 4.6809, validation acc: 17.3486\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 19\n",
            "\n",
            "Epoch [19/50], Step [0/815], Loss: 3.5563\n",
            "Epoch [19/50], Step [20/815], Loss: 3.7746\n",
            "Epoch [19/50], Step [40/815], Loss: 4.1893\n",
            "Epoch [19/50], Step [60/815], Loss: 3.9918\n",
            "Epoch [19/50], Step [80/815], Loss: 4.2425\n",
            "Epoch [19/50], Step [100/815], Loss: 4.5223\n",
            "Epoch [19/50], Step [120/815], Loss: 4.1820\n",
            "Epoch [19/50], Step [140/815], Loss: 3.6771\n",
            "Epoch [19/50], Step [160/815], Loss: 3.7158\n",
            "Epoch [19/50], Step [180/815], Loss: 4.7184\n",
            "Epoch [19/50], Step [200/815], Loss: 4.7491\n",
            "Epoch [19/50], Step [220/815], Loss: 4.5680\n",
            "Epoch [19/50], Step [240/815], Loss: 4.4951\n",
            "Epoch [19/50], Step [260/815], Loss: 3.8744\n",
            "Epoch [19/50], Step [280/815], Loss: 4.1185\n",
            "Epoch [19/50], Step [300/815], Loss: 4.1728\n",
            "Epoch [19/50], Step [320/815], Loss: 4.1326\n",
            "Epoch [19/50], Step [340/815], Loss: 4.2156\n",
            "Epoch [19/50], Step [360/815], Loss: 3.8812\n",
            "Epoch [19/50], Step [380/815], Loss: 4.3471\n",
            "Epoch [19/50], Step [400/815], Loss: 4.1893\n",
            "Epoch [19/50], Step [420/815], Loss: 4.3199\n",
            "Epoch [19/50], Step [440/815], Loss: 4.3164\n",
            "Epoch [19/50], Step [460/815], Loss: 4.1693\n",
            "Epoch [19/50], Step [480/815], Loss: 4.1545\n",
            "Epoch [19/50], Step [500/815], Loss: 4.4898\n",
            "Epoch [19/50], Step [520/815], Loss: 4.2079\n",
            "Epoch [19/50], Step [540/815], Loss: 3.9107\n",
            "Epoch [19/50], Step [560/815], Loss: 3.8676\n",
            "Epoch [19/50], Step [580/815], Loss: 4.0303\n",
            "Epoch [19/50], Step [600/815], Loss: 4.0532\n",
            "Epoch [19/50], Step [620/815], Loss: 4.2999\n",
            "Epoch [19/50], Step [640/815], Loss: 3.9937\n",
            "Epoch [19/50], Step [660/815], Loss: 4.3230\n",
            "Epoch [19/50], Step [680/815], Loss: 4.1895\n",
            "Epoch [19/50], Step [700/815], Loss: 4.1567\n",
            "Epoch [19/50], Step [720/815], Loss: 3.8962\n",
            "Epoch [19/50], Step [740/815], Loss: 3.7215\n",
            "Epoch [19/50], Step [760/815], Loss: 4.1932\n",
            "Epoch [19/50], Step [780/815], Loss: 4.2587\n",
            "Epoch [19/50], Step [800/815], Loss: 3.7081\n",
            "\n",
            "train-loss: 4.6482, train-acc: 23.8089\n",
            "validation loss: 4.6556, validation acc: 17.6471\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 20\n",
            "\n",
            "Epoch [20/50], Step [0/815], Loss: 4.1337\n",
            "Epoch [20/50], Step [20/815], Loss: 4.2000\n",
            "Epoch [20/50], Step [40/815], Loss: 3.8654\n",
            "Epoch [20/50], Step [60/815], Loss: 3.8281\n",
            "Epoch [20/50], Step [80/815], Loss: 3.8877\n",
            "Epoch [20/50], Step [100/815], Loss: 4.0502\n",
            "Epoch [20/50], Step [120/815], Loss: 4.3511\n",
            "Epoch [20/50], Step [140/815], Loss: 4.2427\n",
            "Epoch [20/50], Step [160/815], Loss: 4.1572\n",
            "Epoch [20/50], Step [180/815], Loss: 3.7817\n",
            "Epoch [20/50], Step [200/815], Loss: 4.4560\n",
            "Epoch [20/50], Step [220/815], Loss: 4.2630\n",
            "Epoch [20/50], Step [240/815], Loss: 4.3903\n",
            "Epoch [20/50], Step [260/815], Loss: 4.2052\n",
            "Epoch [20/50], Step [280/815], Loss: 3.7361\n",
            "Epoch [20/50], Step [300/815], Loss: 3.7984\n",
            "Epoch [20/50], Step [320/815], Loss: 3.9552\n",
            "Epoch [20/50], Step [340/815], Loss: 3.8013\n",
            "Epoch [20/50], Step [360/815], Loss: 4.0864\n",
            "Epoch [20/50], Step [380/815], Loss: 3.6535\n",
            "Epoch [20/50], Step [400/815], Loss: 4.0259\n",
            "Epoch [20/50], Step [420/815], Loss: 3.8170\n",
            "Epoch [20/50], Step [440/815], Loss: 3.9527\n",
            "Epoch [20/50], Step [460/815], Loss: 4.4417\n",
            "Epoch [20/50], Step [480/815], Loss: 4.3451\n",
            "Epoch [20/50], Step [500/815], Loss: 4.0097\n",
            "Epoch [20/50], Step [520/815], Loss: 3.8875\n",
            "Epoch [20/50], Step [540/815], Loss: 4.0967\n",
            "Epoch [20/50], Step [560/815], Loss: 4.2570\n",
            "Epoch [20/50], Step [580/815], Loss: 3.8540\n",
            "Epoch [20/50], Step [600/815], Loss: 4.1243\n",
            "Epoch [20/50], Step [620/815], Loss: 3.9023\n",
            "Epoch [20/50], Step [640/815], Loss: 3.8585\n",
            "Epoch [20/50], Step [660/815], Loss: 3.9861\n",
            "Epoch [20/50], Step [680/815], Loss: 3.8996\n",
            "Epoch [20/50], Step [700/815], Loss: 4.0448\n",
            "Epoch [20/50], Step [720/815], Loss: 4.3735\n",
            "Epoch [20/50], Step [740/815], Loss: 4.1231\n",
            "Epoch [20/50], Step [760/815], Loss: 3.5055\n",
            "Epoch [20/50], Step [780/815], Loss: 3.8793\n",
            "Epoch [20/50], Step [800/815], Loss: 3.6827\n",
            "\n",
            "train-loss: 4.6196, train-acc: 24.9877\n",
            "validation loss: 4.6312, validation acc: 17.9953\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 21\n",
            "\n",
            "Epoch [21/50], Step [0/815], Loss: 3.4540\n",
            "Epoch [21/50], Step [20/815], Loss: 4.0055\n",
            "Epoch [21/50], Step [40/815], Loss: 3.7269\n",
            "Epoch [21/50], Step [60/815], Loss: 4.2306\n",
            "Epoch [21/50], Step [80/815], Loss: 4.1857\n",
            "Epoch [21/50], Step [100/815], Loss: 4.1776\n",
            "Epoch [21/50], Step [120/815], Loss: 4.0302\n",
            "Epoch [21/50], Step [140/815], Loss: 4.2138\n",
            "Epoch [21/50], Step [160/815], Loss: 3.8117\n",
            "Epoch [21/50], Step [180/815], Loss: 3.9712\n",
            "Epoch [21/50], Step [200/815], Loss: 4.5557\n",
            "Epoch [21/50], Step [220/815], Loss: 4.0526\n",
            "Epoch [21/50], Step [240/815], Loss: 4.4987\n",
            "Epoch [21/50], Step [260/815], Loss: 3.9114\n",
            "Epoch [21/50], Step [280/815], Loss: 4.0773\n",
            "Epoch [21/50], Step [300/815], Loss: 3.6175\n",
            "Epoch [21/50], Step [320/815], Loss: 4.0607\n",
            "Epoch [21/50], Step [340/815], Loss: 3.9143\n",
            "Epoch [21/50], Step [360/815], Loss: 4.0004\n",
            "Epoch [21/50], Step [380/815], Loss: 3.9183\n",
            "Epoch [21/50], Step [400/815], Loss: 4.2644\n",
            "Epoch [21/50], Step [420/815], Loss: 4.3016\n",
            "Epoch [21/50], Step [440/815], Loss: 3.8070\n",
            "Epoch [21/50], Step [460/815], Loss: 4.2064\n",
            "Epoch [21/50], Step [480/815], Loss: 4.4023\n",
            "Epoch [21/50], Step [500/815], Loss: 3.8311\n",
            "Epoch [21/50], Step [520/815], Loss: 4.3506\n",
            "Epoch [21/50], Step [540/815], Loss: 3.8478\n",
            "Epoch [21/50], Step [560/815], Loss: 4.1265\n",
            "Epoch [21/50], Step [580/815], Loss: 4.0549\n",
            "Epoch [21/50], Step [600/815], Loss: 3.7054\n",
            "Epoch [21/50], Step [620/815], Loss: 3.8482\n",
            "Epoch [21/50], Step [640/815], Loss: 3.8381\n",
            "Epoch [21/50], Step [660/815], Loss: 3.9462\n",
            "Epoch [21/50], Step [680/815], Loss: 4.3016\n",
            "Epoch [21/50], Step [700/815], Loss: 3.7993\n",
            "Epoch [21/50], Step [720/815], Loss: 3.9315\n",
            "Epoch [21/50], Step [740/815], Loss: 4.0305\n",
            "Epoch [21/50], Step [760/815], Loss: 3.8764\n",
            "Epoch [21/50], Step [780/815], Loss: 3.8881\n",
            "Epoch [21/50], Step [800/815], Loss: 3.9146\n",
            "\n",
            "train-loss: 4.5917, train-acc: 26.0683\n",
            "validation loss: 4.6067, validation acc: 19.3011\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 22\n",
            "\n",
            "Epoch [22/50], Step [0/815], Loss: 4.1348\n",
            "Epoch [22/50], Step [20/815], Loss: 4.2804\n",
            "Epoch [22/50], Step [40/815], Loss: 3.8198\n",
            "Epoch [22/50], Step [60/815], Loss: 4.0650\n",
            "Epoch [22/50], Step [80/815], Loss: 3.9831\n",
            "Epoch [22/50], Step [100/815], Loss: 3.9667\n",
            "Epoch [22/50], Step [120/815], Loss: 3.7493\n",
            "Epoch [22/50], Step [140/815], Loss: 4.0019\n",
            "Epoch [22/50], Step [160/815], Loss: 4.0628\n",
            "Epoch [22/50], Step [180/815], Loss: 3.9013\n",
            "Epoch [22/50], Step [200/815], Loss: 4.1722\n",
            "Epoch [22/50], Step [220/815], Loss: 4.2004\n",
            "Epoch [22/50], Step [240/815], Loss: 4.1022\n",
            "Epoch [22/50], Step [260/815], Loss: 4.1011\n",
            "Epoch [22/50], Step [280/815], Loss: 4.2241\n",
            "Epoch [22/50], Step [300/815], Loss: 3.5875\n",
            "Epoch [22/50], Step [320/815], Loss: 3.6195\n",
            "Epoch [22/50], Step [340/815], Loss: 4.3519\n",
            "Epoch [22/50], Step [360/815], Loss: 4.2333\n",
            "Epoch [22/50], Step [380/815], Loss: 3.9556\n",
            "Epoch [22/50], Step [400/815], Loss: 3.8309\n",
            "Epoch [22/50], Step [420/815], Loss: 3.9590\n",
            "Epoch [22/50], Step [440/815], Loss: 3.5152\n",
            "Epoch [22/50], Step [460/815], Loss: 4.2171\n",
            "Epoch [22/50], Step [480/815], Loss: 3.4896\n",
            "Epoch [22/50], Step [500/815], Loss: 3.4806\n",
            "Epoch [22/50], Step [520/815], Loss: 4.1582\n",
            "Epoch [22/50], Step [540/815], Loss: 4.1428\n",
            "Epoch [22/50], Step [560/815], Loss: 3.9986\n",
            "Epoch [22/50], Step [580/815], Loss: 4.2569\n",
            "Epoch [22/50], Step [600/815], Loss: 3.8982\n",
            "Epoch [22/50], Step [620/815], Loss: 3.8724\n",
            "Epoch [22/50], Step [640/815], Loss: 4.1639\n",
            "Epoch [22/50], Step [660/815], Loss: 4.0797\n",
            "Epoch [22/50], Step [680/815], Loss: 3.8429\n",
            "Epoch [22/50], Step [700/815], Loss: 4.3232\n",
            "Epoch [22/50], Step [720/815], Loss: 4.5593\n",
            "Epoch [22/50], Step [740/815], Loss: 3.8873\n",
            "Epoch [22/50], Step [760/815], Loss: 4.0430\n",
            "Epoch [22/50], Step [780/815], Loss: 3.9860\n",
            "Epoch [22/50], Step [800/815], Loss: 4.1023\n",
            "\n",
            "train-loss: 4.5643, train-acc: 27.0383\n",
            "validation loss: 4.5833, validation acc: 19.6244\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 23\n",
            "\n",
            "Epoch [23/50], Step [0/815], Loss: 3.6783\n",
            "Epoch [23/50], Step [20/815], Loss: 4.0679\n",
            "Epoch [23/50], Step [40/815], Loss: 3.5622\n",
            "Epoch [23/50], Step [60/815], Loss: 4.4699\n",
            "Epoch [23/50], Step [80/815], Loss: 3.8325\n",
            "Epoch [23/50], Step [100/815], Loss: 4.5776\n",
            "Epoch [23/50], Step [120/815], Loss: 4.0932\n",
            "Epoch [23/50], Step [140/815], Loss: 3.6541\n",
            "Epoch [23/50], Step [160/815], Loss: 3.9315\n",
            "Epoch [23/50], Step [180/815], Loss: 3.6455\n",
            "Epoch [23/50], Step [200/815], Loss: 4.0895\n",
            "Epoch [23/50], Step [220/815], Loss: 4.3584\n",
            "Epoch [23/50], Step [240/815], Loss: 4.0768\n",
            "Epoch [23/50], Step [260/815], Loss: 4.1308\n",
            "Epoch [23/50], Step [280/815], Loss: 3.9008\n",
            "Epoch [23/50], Step [300/815], Loss: 4.0064\n",
            "Epoch [23/50], Step [320/815], Loss: 3.8467\n",
            "Epoch [23/50], Step [340/815], Loss: 3.7055\n",
            "Epoch [23/50], Step [360/815], Loss: 4.3554\n",
            "Epoch [23/50], Step [380/815], Loss: 4.0754\n",
            "Epoch [23/50], Step [400/815], Loss: 4.1363\n",
            "Epoch [23/50], Step [420/815], Loss: 3.7534\n",
            "Epoch [23/50], Step [440/815], Loss: 4.1847\n",
            "Epoch [23/50], Step [460/815], Loss: 3.7219\n",
            "Epoch [23/50], Step [480/815], Loss: 3.9403\n",
            "Epoch [23/50], Step [500/815], Loss: 4.3202\n",
            "Epoch [23/50], Step [520/815], Loss: 3.6614\n",
            "Epoch [23/50], Step [540/815], Loss: 4.1796\n",
            "Epoch [23/50], Step [560/815], Loss: 4.0147\n",
            "Epoch [23/50], Step [580/815], Loss: 3.7264\n",
            "Epoch [23/50], Step [600/815], Loss: 3.9716\n",
            "Epoch [23/50], Step [620/815], Loss: 3.8743\n",
            "Epoch [23/50], Step [640/815], Loss: 3.7960\n",
            "Epoch [23/50], Step [660/815], Loss: 4.1993\n",
            "Epoch [23/50], Step [680/815], Loss: 3.9654\n",
            "Epoch [23/50], Step [700/815], Loss: 4.0680\n",
            "Epoch [23/50], Step [720/815], Loss: 3.7679\n",
            "Epoch [23/50], Step [740/815], Loss: 3.9106\n",
            "Epoch [23/50], Step [760/815], Loss: 4.1228\n",
            "Epoch [23/50], Step [780/815], Loss: 3.8819\n",
            "Epoch [23/50], Step [800/815], Loss: 3.4779\n",
            "\n",
            "train-loss: 4.5374, train-acc: 28.4995\n",
            "validation loss: 4.5605, validation acc: 20.2835\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 24\n",
            "\n",
            "Epoch [24/50], Step [0/815], Loss: 3.9204\n",
            "Epoch [24/50], Step [20/815], Loss: 4.0210\n",
            "Epoch [24/50], Step [40/815], Loss: 3.7902\n",
            "Epoch [24/50], Step [60/815], Loss: 3.6725\n",
            "Epoch [24/50], Step [80/815], Loss: 3.7491\n",
            "Epoch [24/50], Step [100/815], Loss: 3.7177\n",
            "Epoch [24/50], Step [120/815], Loss: 3.7472\n",
            "Epoch [24/50], Step [140/815], Loss: 3.8936\n",
            "Epoch [24/50], Step [160/815], Loss: 3.9032\n",
            "Epoch [24/50], Step [180/815], Loss: 4.0694\n",
            "Epoch [24/50], Step [200/815], Loss: 4.0732\n",
            "Epoch [24/50], Step [220/815], Loss: 3.8962\n",
            "Epoch [24/50], Step [240/815], Loss: 3.4728\n",
            "Epoch [24/50], Step [260/815], Loss: 4.1615\n",
            "Epoch [24/50], Step [280/815], Loss: 3.9835\n",
            "Epoch [24/50], Step [300/815], Loss: 4.2460\n",
            "Epoch [24/50], Step [320/815], Loss: 3.7498\n",
            "Epoch [24/50], Step [340/815], Loss: 4.0177\n",
            "Epoch [24/50], Step [360/815], Loss: 3.4019\n",
            "Epoch [24/50], Step [380/815], Loss: 3.3328\n",
            "Epoch [24/50], Step [400/815], Loss: 3.9558\n",
            "Epoch [24/50], Step [420/815], Loss: 3.8837\n",
            "Epoch [24/50], Step [440/815], Loss: 3.8457\n",
            "Epoch [24/50], Step [460/815], Loss: 3.8936\n",
            "Epoch [24/50], Step [480/815], Loss: 3.9561\n",
            "Epoch [24/50], Step [500/815], Loss: 3.7629\n",
            "Epoch [24/50], Step [520/815], Loss: 3.5985\n",
            "Epoch [24/50], Step [540/815], Loss: 4.1716\n",
            "Epoch [24/50], Step [560/815], Loss: 3.6140\n",
            "Epoch [24/50], Step [580/815], Loss: 4.2230\n",
            "Epoch [24/50], Step [600/815], Loss: 3.4770\n",
            "Epoch [24/50], Step [620/815], Loss: 4.0823\n",
            "Epoch [24/50], Step [640/815], Loss: 3.8255\n",
            "Epoch [24/50], Step [660/815], Loss: 4.3716\n",
            "Epoch [24/50], Step [680/815], Loss: 4.2911\n",
            "Epoch [24/50], Step [700/815], Loss: 3.9191\n",
            "Epoch [24/50], Step [720/815], Loss: 4.0483\n",
            "Epoch [24/50], Step [740/815], Loss: 3.8956\n",
            "Epoch [24/50], Step [760/815], Loss: 4.1669\n",
            "Epoch [24/50], Step [780/815], Loss: 4.1302\n",
            "Epoch [24/50], Step [800/815], Loss: 3.7548\n",
            "\n",
            "train-loss: 4.5113, train-acc: 28.6100\n",
            "validation loss: 4.5381, validation acc: 20.3955\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 25\n",
            "\n",
            "Epoch [25/50], Step [0/815], Loss: 3.8838\n",
            "Epoch [25/50], Step [20/815], Loss: 3.8264\n",
            "Epoch [25/50], Step [40/815], Loss: 3.6426\n",
            "Epoch [25/50], Step [60/815], Loss: 4.0783\n",
            "Epoch [25/50], Step [80/815], Loss: 4.0561\n",
            "Epoch [25/50], Step [100/815], Loss: 3.5703\n",
            "Epoch [25/50], Step [120/815], Loss: 3.5968\n",
            "Epoch [25/50], Step [140/815], Loss: 4.0087\n",
            "Epoch [25/50], Step [160/815], Loss: 3.9072\n",
            "Epoch [25/50], Step [180/815], Loss: 3.6967\n",
            "Epoch [25/50], Step [200/815], Loss: 3.6693\n",
            "Epoch [25/50], Step [220/815], Loss: 4.2579\n",
            "Epoch [25/50], Step [240/815], Loss: 3.8088\n",
            "Epoch [25/50], Step [260/815], Loss: 3.3116\n",
            "Epoch [25/50], Step [280/815], Loss: 4.0810\n",
            "Epoch [25/50], Step [300/815], Loss: 3.6770\n",
            "Epoch [25/50], Step [320/815], Loss: 4.2226\n",
            "Epoch [25/50], Step [340/815], Loss: 3.8864\n",
            "Epoch [25/50], Step [360/815], Loss: 3.7707\n",
            "Epoch [25/50], Step [380/815], Loss: 3.7390\n",
            "Epoch [25/50], Step [400/815], Loss: 3.4252\n",
            "Epoch [25/50], Step [420/815], Loss: 3.6336\n",
            "Epoch [25/50], Step [440/815], Loss: 3.1380\n",
            "Epoch [25/50], Step [460/815], Loss: 3.8562\n",
            "Epoch [25/50], Step [480/815], Loss: 4.2423\n",
            "Epoch [25/50], Step [500/815], Loss: 4.2193\n",
            "Epoch [25/50], Step [520/815], Loss: 3.9360\n",
            "Epoch [25/50], Step [540/815], Loss: 3.3922\n",
            "Epoch [25/50], Step [560/815], Loss: 3.6962\n",
            "Epoch [25/50], Step [580/815], Loss: 3.8639\n",
            "Epoch [25/50], Step [600/815], Loss: 3.8483\n",
            "Epoch [25/50], Step [620/815], Loss: 3.4839\n",
            "Epoch [25/50], Step [640/815], Loss: 3.7684\n",
            "Epoch [25/50], Step [660/815], Loss: 3.6030\n",
            "Epoch [25/50], Step [680/815], Loss: 3.5858\n",
            "Epoch [25/50], Step [700/815], Loss: 3.7985\n",
            "Epoch [25/50], Step [720/815], Loss: 3.8570\n",
            "Epoch [25/50], Step [740/815], Loss: 3.6757\n",
            "Epoch [25/50], Step [760/815], Loss: 4.2463\n",
            "Epoch [25/50], Step [780/815], Loss: 3.7427\n",
            "Epoch [25/50], Step [800/815], Loss: 4.1693\n",
            "\n",
            "train-loss: 4.4856, train-acc: 30.3045\n",
            "validation loss: 4.5163, validation acc: 20.9427\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 26\n",
            "\n",
            "Epoch [26/50], Step [0/815], Loss: 3.8525\n",
            "Epoch [26/50], Step [20/815], Loss: 3.9515\n",
            "Epoch [26/50], Step [40/815], Loss: 4.0902\n",
            "Epoch [26/50], Step [60/815], Loss: 3.7974\n",
            "Epoch [26/50], Step [80/815], Loss: 4.1355\n",
            "Epoch [26/50], Step [100/815], Loss: 3.9921\n",
            "Epoch [26/50], Step [120/815], Loss: 3.5138\n",
            "Epoch [26/50], Step [140/815], Loss: 3.5897\n",
            "Epoch [26/50], Step [160/815], Loss: 4.0075\n",
            "Epoch [26/50], Step [180/815], Loss: 4.0567\n",
            "Epoch [26/50], Step [200/815], Loss: 3.8345\n",
            "Epoch [26/50], Step [220/815], Loss: 3.9593\n",
            "Epoch [26/50], Step [240/815], Loss: 3.9704\n",
            "Epoch [26/50], Step [260/815], Loss: 4.1576\n",
            "Epoch [26/50], Step [280/815], Loss: 3.4669\n",
            "Epoch [26/50], Step [300/815], Loss: 4.0904\n",
            "Epoch [26/50], Step [320/815], Loss: 3.6723\n",
            "Epoch [26/50], Step [340/815], Loss: 3.9593\n",
            "Epoch [26/50], Step [360/815], Loss: 3.6413\n",
            "Epoch [26/50], Step [380/815], Loss: 3.6995\n",
            "Epoch [26/50], Step [400/815], Loss: 3.7984\n",
            "Epoch [26/50], Step [420/815], Loss: 3.6568\n",
            "Epoch [26/50], Step [440/815], Loss: 4.3164\n",
            "Epoch [26/50], Step [460/815], Loss: 3.3331\n",
            "Epoch [26/50], Step [480/815], Loss: 4.1253\n",
            "Epoch [26/50], Step [500/815], Loss: 4.0128\n",
            "Epoch [26/50], Step [520/815], Loss: 4.1077\n",
            "Epoch [26/50], Step [540/815], Loss: 4.0745\n",
            "Epoch [26/50], Step [560/815], Loss: 4.2669\n",
            "Epoch [26/50], Step [580/815], Loss: 3.6297\n",
            "Epoch [26/50], Step [600/815], Loss: 3.5892\n",
            "Epoch [26/50], Step [620/815], Loss: 3.6138\n",
            "Epoch [26/50], Step [640/815], Loss: 3.9165\n",
            "Epoch [26/50], Step [660/815], Loss: 3.7971\n",
            "Epoch [26/50], Step [680/815], Loss: 3.4941\n",
            "Epoch [26/50], Step [700/815], Loss: 4.0141\n",
            "Epoch [26/50], Step [720/815], Loss: 4.0517\n",
            "Epoch [26/50], Step [740/815], Loss: 3.7152\n",
            "Epoch [26/50], Step [760/815], Loss: 3.8403\n",
            "Epoch [26/50], Step [780/815], Loss: 4.0568\n",
            "Epoch [26/50], Step [800/815], Loss: 4.0056\n",
            "\n",
            "train-loss: 4.4601, train-acc: 30.3782\n",
            "validation loss: 4.4940, validation acc: 21.5396\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 27\n",
            "\n",
            "Epoch [27/50], Step [0/815], Loss: 3.9842\n",
            "Epoch [27/50], Step [20/815], Loss: 3.9649\n",
            "Epoch [27/50], Step [40/815], Loss: 4.0155\n",
            "Epoch [27/50], Step [60/815], Loss: 3.8714\n",
            "Epoch [27/50], Step [80/815], Loss: 3.5827\n",
            "Epoch [27/50], Step [100/815], Loss: 3.9142\n",
            "Epoch [27/50], Step [120/815], Loss: 3.7747\n",
            "Epoch [27/50], Step [140/815], Loss: 4.1128\n",
            "Epoch [27/50], Step [160/815], Loss: 3.7016\n",
            "Epoch [27/50], Step [180/815], Loss: 3.9668\n",
            "Epoch [27/50], Step [200/815], Loss: 3.8316\n",
            "Epoch [27/50], Step [220/815], Loss: 3.8884\n",
            "Epoch [27/50], Step [240/815], Loss: 4.0558\n",
            "Epoch [27/50], Step [260/815], Loss: 3.9336\n",
            "Epoch [27/50], Step [280/815], Loss: 3.3478\n",
            "Epoch [27/50], Step [300/815], Loss: 3.9082\n",
            "Epoch [27/50], Step [320/815], Loss: 3.7046\n",
            "Epoch [27/50], Step [340/815], Loss: 3.4342\n",
            "Epoch [27/50], Step [360/815], Loss: 3.6695\n",
            "Epoch [27/50], Step [380/815], Loss: 3.5089\n",
            "Epoch [27/50], Step [400/815], Loss: 4.0176\n",
            "Epoch [27/50], Step [420/815], Loss: 3.5595\n",
            "Epoch [27/50], Step [440/815], Loss: 3.8991\n",
            "Epoch [27/50], Step [460/815], Loss: 3.5231\n",
            "Epoch [27/50], Step [480/815], Loss: 3.5214\n",
            "Epoch [27/50], Step [500/815], Loss: 4.0705\n",
            "Epoch [27/50], Step [520/815], Loss: 4.0376\n",
            "Epoch [27/50], Step [540/815], Loss: 4.0355\n",
            "Epoch [27/50], Step [560/815], Loss: 3.7407\n",
            "Epoch [27/50], Step [580/815], Loss: 4.0758\n",
            "Epoch [27/50], Step [600/815], Loss: 3.9916\n",
            "Epoch [27/50], Step [620/815], Loss: 3.1417\n",
            "Epoch [27/50], Step [640/815], Loss: 4.0986\n",
            "Epoch [27/50], Step [660/815], Loss: 3.6284\n",
            "Epoch [27/50], Step [680/815], Loss: 4.1021\n",
            "Epoch [27/50], Step [700/815], Loss: 3.6831\n",
            "Epoch [27/50], Step [720/815], Loss: 3.4531\n",
            "Epoch [27/50], Step [740/815], Loss: 3.8479\n",
            "Epoch [27/50], Step [760/815], Loss: 3.9675\n",
            "Epoch [27/50], Step [780/815], Loss: 3.3271\n",
            "Epoch [27/50], Step [800/815], Loss: 3.9166\n",
            "\n",
            "train-loss: 4.4355, train-acc: 30.7957\n",
            "validation loss: 4.4731, validation acc: 22.2609\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 28\n",
            "\n",
            "Epoch [28/50], Step [0/815], Loss: 3.5856\n",
            "Epoch [28/50], Step [20/815], Loss: 3.2566\n",
            "Epoch [28/50], Step [40/815], Loss: 3.8559\n",
            "Epoch [28/50], Step [60/815], Loss: 3.3884\n",
            "Epoch [28/50], Step [80/815], Loss: 3.7671\n",
            "Epoch [28/50], Step [100/815], Loss: 3.7683\n",
            "Epoch [28/50], Step [120/815], Loss: 3.4684\n",
            "Epoch [28/50], Step [140/815], Loss: 3.5659\n",
            "Epoch [28/50], Step [160/815], Loss: 3.8229\n",
            "Epoch [28/50], Step [180/815], Loss: 3.5426\n",
            "Epoch [28/50], Step [200/815], Loss: 3.5915\n",
            "Epoch [28/50], Step [220/815], Loss: 3.8732\n",
            "Epoch [28/50], Step [240/815], Loss: 3.8540\n",
            "Epoch [28/50], Step [260/815], Loss: 3.9554\n",
            "Epoch [28/50], Step [280/815], Loss: 4.0266\n",
            "Epoch [28/50], Step [300/815], Loss: 3.8176\n",
            "Epoch [28/50], Step [320/815], Loss: 3.8117\n",
            "Epoch [28/50], Step [340/815], Loss: 3.5008\n",
            "Epoch [28/50], Step [360/815], Loss: 4.0684\n",
            "Epoch [28/50], Step [380/815], Loss: 3.5193\n",
            "Epoch [28/50], Step [400/815], Loss: 3.5933\n",
            "Epoch [28/50], Step [420/815], Loss: 3.8907\n",
            "Epoch [28/50], Step [440/815], Loss: 3.6436\n",
            "Epoch [28/50], Step [460/815], Loss: 3.6675\n",
            "Epoch [28/50], Step [480/815], Loss: 3.9645\n",
            "Epoch [28/50], Step [500/815], Loss: 3.9391\n",
            "Epoch [28/50], Step [520/815], Loss: 3.8634\n",
            "Epoch [28/50], Step [540/815], Loss: 3.6539\n",
            "Epoch [28/50], Step [560/815], Loss: 3.9732\n",
            "Epoch [28/50], Step [580/815], Loss: 3.6993\n",
            "Epoch [28/50], Step [600/815], Loss: 4.1347\n",
            "Epoch [28/50], Step [620/815], Loss: 3.6079\n",
            "Epoch [28/50], Step [640/815], Loss: 3.8935\n",
            "Epoch [28/50], Step [660/815], Loss: 3.4636\n",
            "Epoch [28/50], Step [680/815], Loss: 3.5766\n",
            "Epoch [28/50], Step [700/815], Loss: 3.7168\n",
            "Epoch [28/50], Step [720/815], Loss: 3.3713\n",
            "Epoch [28/50], Step [740/815], Loss: 3.8031\n",
            "Epoch [28/50], Step [760/815], Loss: 3.7388\n",
            "Epoch [28/50], Step [780/815], Loss: 3.5115\n",
            "Epoch [28/50], Step [800/815], Loss: 3.8424\n",
            "\n",
            "train-loss: 4.4109, train-acc: 32.1955\n",
            "validation loss: 4.4524, validation acc: 22.8205\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 29\n",
            "\n",
            "Epoch [29/50], Step [0/815], Loss: 4.6938\n",
            "Epoch [29/50], Step [20/815], Loss: 3.4191\n",
            "Epoch [29/50], Step [40/815], Loss: 3.8366\n",
            "Epoch [29/50], Step [60/815], Loss: 3.3350\n",
            "Epoch [29/50], Step [80/815], Loss: 3.7085\n",
            "Epoch [29/50], Step [100/815], Loss: 3.4477\n",
            "Epoch [29/50], Step [120/815], Loss: 4.1351\n",
            "Epoch [29/50], Step [140/815], Loss: 3.5359\n",
            "Epoch [29/50], Step [160/815], Loss: 3.7151\n",
            "Epoch [29/50], Step [180/815], Loss: 3.4964\n",
            "Epoch [29/50], Step [200/815], Loss: 3.5681\n",
            "Epoch [29/50], Step [220/815], Loss: 4.5179\n",
            "Epoch [29/50], Step [240/815], Loss: 3.3039\n",
            "Epoch [29/50], Step [260/815], Loss: 3.9429\n",
            "Epoch [29/50], Step [280/815], Loss: 3.9988\n",
            "Epoch [29/50], Step [300/815], Loss: 3.8350\n",
            "Epoch [29/50], Step [320/815], Loss: 3.8856\n",
            "Epoch [29/50], Step [340/815], Loss: 4.3283\n",
            "Epoch [29/50], Step [360/815], Loss: 4.0621\n",
            "Epoch [29/50], Step [380/815], Loss: 3.7885\n",
            "Epoch [29/50], Step [400/815], Loss: 3.7260\n",
            "Epoch [29/50], Step [420/815], Loss: 3.4642\n",
            "Epoch [29/50], Step [440/815], Loss: 3.9565\n",
            "Epoch [29/50], Step [460/815], Loss: 3.8665\n",
            "Epoch [29/50], Step [480/815], Loss: 3.6604\n",
            "Epoch [29/50], Step [500/815], Loss: 3.9477\n",
            "Epoch [29/50], Step [520/815], Loss: 3.4758\n",
            "Epoch [29/50], Step [540/815], Loss: 3.8553\n",
            "Epoch [29/50], Step [560/815], Loss: 3.6896\n",
            "Epoch [29/50], Step [580/815], Loss: 4.1108\n",
            "Epoch [29/50], Step [600/815], Loss: 3.6008\n",
            "Epoch [29/50], Step [620/815], Loss: 3.8125\n",
            "Epoch [29/50], Step [640/815], Loss: 3.6232\n",
            "Epoch [29/50], Step [660/815], Loss: 4.0446\n",
            "Epoch [29/50], Step [680/815], Loss: 3.7176\n",
            "Epoch [29/50], Step [700/815], Loss: 4.0957\n",
            "Epoch [29/50], Step [720/815], Loss: 4.2898\n",
            "Epoch [29/50], Step [740/815], Loss: 3.2553\n",
            "Epoch [29/50], Step [760/815], Loss: 3.8512\n",
            "Epoch [29/50], Step [780/815], Loss: 3.7104\n",
            "Epoch [29/50], Step [800/815], Loss: 3.2785\n",
            "\n",
            "train-loss: 4.3868, train-acc: 33.3129\n",
            "validation loss: 4.4325, validation acc: 23.0941\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 30\n",
            "\n",
            "Epoch [30/50], Step [0/815], Loss: 3.7625\n",
            "Epoch [30/50], Step [20/815], Loss: 3.5860\n",
            "Epoch [30/50], Step [40/815], Loss: 3.7305\n",
            "Epoch [30/50], Step [60/815], Loss: 3.5733\n",
            "Epoch [30/50], Step [80/815], Loss: 3.5488\n",
            "Epoch [30/50], Step [100/815], Loss: 3.6880\n",
            "Epoch [30/50], Step [120/815], Loss: 3.6097\n",
            "Epoch [30/50], Step [140/815], Loss: 3.6176\n",
            "Epoch [30/50], Step [160/815], Loss: 3.4457\n",
            "Epoch [30/50], Step [180/815], Loss: 3.9545\n",
            "Epoch [30/50], Step [200/815], Loss: 3.5573\n",
            "Epoch [30/50], Step [220/815], Loss: 3.7020\n",
            "Epoch [30/50], Step [240/815], Loss: 3.7308\n",
            "Epoch [30/50], Step [260/815], Loss: 3.7350\n",
            "Epoch [30/50], Step [280/815], Loss: 3.5605\n",
            "Epoch [30/50], Step [300/815], Loss: 3.2869\n",
            "Epoch [30/50], Step [320/815], Loss: 3.6619\n",
            "Epoch [30/50], Step [340/815], Loss: 3.1945\n",
            "Epoch [30/50], Step [360/815], Loss: 3.9029\n",
            "Epoch [30/50], Step [380/815], Loss: 4.0218\n",
            "Epoch [30/50], Step [400/815], Loss: 4.1512\n",
            "Epoch [30/50], Step [420/815], Loss: 4.1139\n",
            "Epoch [30/50], Step [440/815], Loss: 3.4818\n",
            "Epoch [30/50], Step [460/815], Loss: 3.9010\n",
            "Epoch [30/50], Step [480/815], Loss: 3.2595\n",
            "Epoch [30/50], Step [500/815], Loss: 3.8241\n",
            "Epoch [30/50], Step [520/815], Loss: 3.9896\n",
            "Epoch [30/50], Step [540/815], Loss: 3.3740\n",
            "Epoch [30/50], Step [560/815], Loss: 4.1856\n",
            "Epoch [30/50], Step [580/815], Loss: 3.6381\n",
            "Epoch [30/50], Step [600/815], Loss: 4.0471\n",
            "Epoch [30/50], Step [620/815], Loss: 3.7818\n",
            "Epoch [30/50], Step [640/815], Loss: 3.7774\n",
            "Epoch [30/50], Step [660/815], Loss: 3.8507\n",
            "Epoch [30/50], Step [680/815], Loss: 4.2425\n",
            "Epoch [30/50], Step [700/815], Loss: 3.4027\n",
            "Epoch [30/50], Step [720/815], Loss: 3.5048\n",
            "Epoch [30/50], Step [740/815], Loss: 3.6473\n",
            "Epoch [30/50], Step [760/815], Loss: 4.1064\n",
            "Epoch [30/50], Step [780/815], Loss: 3.3005\n",
            "Epoch [30/50], Step [800/815], Loss: 3.3132\n",
            "\n",
            "train-loss: 4.3631, train-acc: 33.2760\n",
            "validation loss: 4.4123, validation acc: 23.0568\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 31\n",
            "\n",
            "Epoch [31/50], Step [0/815], Loss: 3.6593\n",
            "Epoch [31/50], Step [20/815], Loss: 3.6374\n",
            "Epoch [31/50], Step [40/815], Loss: 3.4439\n",
            "Epoch [31/50], Step [60/815], Loss: 3.2269\n",
            "Epoch [31/50], Step [80/815], Loss: 3.4074\n",
            "Epoch [31/50], Step [100/815], Loss: 3.5175\n",
            "Epoch [31/50], Step [120/815], Loss: 3.5239\n",
            "Epoch [31/50], Step [140/815], Loss: 3.3743\n",
            "Epoch [31/50], Step [160/815], Loss: 3.5228\n",
            "Epoch [31/50], Step [180/815], Loss: 3.9161\n",
            "Epoch [31/50], Step [200/815], Loss: 3.7158\n",
            "Epoch [31/50], Step [220/815], Loss: 4.0465\n",
            "Epoch [31/50], Step [240/815], Loss: 3.8128\n",
            "Epoch [31/50], Step [260/815], Loss: 3.7297\n",
            "Epoch [31/50], Step [280/815], Loss: 2.8969\n",
            "Epoch [31/50], Step [300/815], Loss: 3.6954\n",
            "Epoch [31/50], Step [320/815], Loss: 3.2887\n",
            "Epoch [31/50], Step [340/815], Loss: 3.4753\n",
            "Epoch [31/50], Step [360/815], Loss: 3.2777\n",
            "Epoch [31/50], Step [380/815], Loss: 3.0496\n",
            "Epoch [31/50], Step [400/815], Loss: 3.5360\n",
            "Epoch [31/50], Step [420/815], Loss: 3.2049\n",
            "Epoch [31/50], Step [440/815], Loss: 3.6438\n",
            "Epoch [31/50], Step [460/815], Loss: 3.5990\n",
            "Epoch [31/50], Step [480/815], Loss: 3.5174\n",
            "Epoch [31/50], Step [500/815], Loss: 3.4228\n",
            "Epoch [31/50], Step [520/815], Loss: 3.5247\n",
            "Epoch [31/50], Step [540/815], Loss: 3.7122\n",
            "Epoch [31/50], Step [560/815], Loss: 3.8454\n",
            "Epoch [31/50], Step [580/815], Loss: 3.5728\n",
            "Epoch [31/50], Step [600/815], Loss: 3.7242\n",
            "Epoch [31/50], Step [620/815], Loss: 3.5749\n",
            "Epoch [31/50], Step [640/815], Loss: 3.6151\n",
            "Epoch [31/50], Step [660/815], Loss: 3.4733\n",
            "Epoch [31/50], Step [680/815], Loss: 3.5767\n",
            "Epoch [31/50], Step [700/815], Loss: 3.1262\n",
            "Epoch [31/50], Step [720/815], Loss: 3.8243\n",
            "Epoch [31/50], Step [740/815], Loss: 3.4858\n",
            "Epoch [31/50], Step [760/815], Loss: 3.2866\n",
            "Epoch [31/50], Step [780/815], Loss: 3.2418\n",
            "Epoch [31/50], Step [800/815], Loss: 3.7456\n",
            "\n",
            "train-loss: 4.3400, train-acc: 33.9759\n",
            "validation loss: 4.3931, validation acc: 23.1563\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 32\n",
            "\n",
            "Epoch [32/50], Step [0/815], Loss: 3.5981\n",
            "Epoch [32/50], Step [20/815], Loss: 3.7436\n",
            "Epoch [32/50], Step [40/815], Loss: 3.2926\n",
            "Epoch [32/50], Step [60/815], Loss: 3.7530\n",
            "Epoch [32/50], Step [80/815], Loss: 3.7424\n",
            "Epoch [32/50], Step [100/815], Loss: 3.6314\n",
            "Epoch [32/50], Step [120/815], Loss: 3.2504\n",
            "Epoch [32/50], Step [140/815], Loss: 3.8649\n",
            "Epoch [32/50], Step [160/815], Loss: 3.5501\n",
            "Epoch [32/50], Step [180/815], Loss: 3.4227\n",
            "Epoch [32/50], Step [200/815], Loss: 3.9685\n",
            "Epoch [32/50], Step [220/815], Loss: 3.9390\n",
            "Epoch [32/50], Step [240/815], Loss: 3.6613\n",
            "Epoch [32/50], Step [260/815], Loss: 3.7085\n",
            "Epoch [32/50], Step [280/815], Loss: 3.6359\n",
            "Epoch [32/50], Step [300/815], Loss: 3.7883\n",
            "Epoch [32/50], Step [320/815], Loss: 4.0617\n",
            "Epoch [32/50], Step [340/815], Loss: 3.3350\n",
            "Epoch [32/50], Step [360/815], Loss: 3.3963\n",
            "Epoch [32/50], Step [380/815], Loss: 3.6833\n",
            "Epoch [32/50], Step [400/815], Loss: 3.6049\n",
            "Epoch [32/50], Step [420/815], Loss: 3.2380\n",
            "Epoch [32/50], Step [440/815], Loss: 3.5852\n",
            "Epoch [32/50], Step [460/815], Loss: 3.6494\n",
            "Epoch [32/50], Step [480/815], Loss: 3.8765\n",
            "Epoch [32/50], Step [500/815], Loss: 3.7280\n",
            "Epoch [32/50], Step [520/815], Loss: 3.5465\n",
            "Epoch [32/50], Step [540/815], Loss: 3.5655\n",
            "Epoch [32/50], Step [560/815], Loss: 3.6823\n",
            "Epoch [32/50], Step [580/815], Loss: 3.7293\n",
            "Epoch [32/50], Step [600/815], Loss: 3.5785\n",
            "Epoch [32/50], Step [620/815], Loss: 3.2048\n",
            "Epoch [32/50], Step [640/815], Loss: 3.6547\n",
            "Epoch [32/50], Step [660/815], Loss: 3.4904\n",
            "Epoch [32/50], Step [680/815], Loss: 3.8047\n",
            "Epoch [32/50], Step [700/815], Loss: 3.5913\n",
            "Epoch [32/50], Step [720/815], Loss: 4.0671\n",
            "Epoch [32/50], Step [740/815], Loss: 3.7465\n",
            "Epoch [32/50], Step [760/815], Loss: 3.9331\n",
            "Epoch [32/50], Step [780/815], Loss: 3.5964\n",
            "Epoch [32/50], Step [800/815], Loss: 3.6638\n",
            "\n",
            "train-loss: 4.3173, train-acc: 34.3075\n",
            "validation loss: 4.3743, validation acc: 23.6911\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 33\n",
            "\n",
            "Epoch [33/50], Step [0/815], Loss: 3.3689\n",
            "Epoch [33/50], Step [20/815], Loss: 3.4679\n",
            "Epoch [33/50], Step [40/815], Loss: 3.9241\n",
            "Epoch [33/50], Step [60/815], Loss: 3.0205\n",
            "Epoch [33/50], Step [80/815], Loss: 3.6504\n",
            "Epoch [33/50], Step [100/815], Loss: 3.7892\n",
            "Epoch [33/50], Step [120/815], Loss: 3.0073\n",
            "Epoch [33/50], Step [140/815], Loss: 3.5674\n",
            "Epoch [33/50], Step [160/815], Loss: 3.5589\n",
            "Epoch [33/50], Step [180/815], Loss: 3.6403\n",
            "Epoch [33/50], Step [200/815], Loss: 3.3565\n",
            "Epoch [33/50], Step [220/815], Loss: 3.3036\n",
            "Epoch [33/50], Step [240/815], Loss: 3.9026\n",
            "Epoch [33/50], Step [260/815], Loss: 3.9101\n",
            "Epoch [33/50], Step [280/815], Loss: 3.2468\n",
            "Epoch [33/50], Step [300/815], Loss: 2.9246\n",
            "Epoch [33/50], Step [320/815], Loss: 3.9845\n",
            "Epoch [33/50], Step [340/815], Loss: 3.2274\n",
            "Epoch [33/50], Step [360/815], Loss: 3.4844\n",
            "Epoch [33/50], Step [380/815], Loss: 3.3178\n",
            "Epoch [33/50], Step [400/815], Loss: 3.7590\n",
            "Epoch [33/50], Step [420/815], Loss: 3.4778\n",
            "Epoch [33/50], Step [440/815], Loss: 3.9257\n",
            "Epoch [33/50], Step [460/815], Loss: 3.4146\n",
            "Epoch [33/50], Step [480/815], Loss: 3.8141\n",
            "Epoch [33/50], Step [500/815], Loss: 4.1412\n",
            "Epoch [33/50], Step [520/815], Loss: 3.9834\n",
            "Epoch [33/50], Step [540/815], Loss: 3.7745\n",
            "Epoch [33/50], Step [560/815], Loss: 3.5406\n",
            "Epoch [33/50], Step [580/815], Loss: 3.2917\n",
            "Epoch [33/50], Step [600/815], Loss: 2.9237\n",
            "Epoch [33/50], Step [620/815], Loss: 3.3890\n",
            "Epoch [33/50], Step [640/815], Loss: 3.5076\n",
            "Epoch [33/50], Step [660/815], Loss: 3.5838\n",
            "Epoch [33/50], Step [680/815], Loss: 3.3733\n",
            "Epoch [33/50], Step [700/815], Loss: 3.1171\n",
            "Epoch [33/50], Step [720/815], Loss: 3.7020\n",
            "Epoch [33/50], Step [740/815], Loss: 3.4642\n",
            "Epoch [33/50], Step [760/815], Loss: 3.5412\n",
            "Epoch [33/50], Step [780/815], Loss: 2.7742\n",
            "Epoch [33/50], Step [800/815], Loss: 3.5034\n",
            "\n",
            "train-loss: 4.2949, train-acc: 35.3635\n",
            "validation loss: 4.3563, validation acc: 24.6114\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 34\n",
            "\n",
            "Epoch [34/50], Step [0/815], Loss: 3.6214\n",
            "Epoch [34/50], Step [20/815], Loss: 3.5821\n",
            "Epoch [34/50], Step [40/815], Loss: 4.0779\n",
            "Epoch [34/50], Step [60/815], Loss: 3.4641\n",
            "Epoch [34/50], Step [80/815], Loss: 3.2394\n",
            "Epoch [34/50], Step [100/815], Loss: 3.7014\n",
            "Epoch [34/50], Step [120/815], Loss: 3.1467\n",
            "Epoch [34/50], Step [140/815], Loss: 4.0286\n",
            "Epoch [34/50], Step [160/815], Loss: 3.7334\n",
            "Epoch [34/50], Step [180/815], Loss: 3.6153\n",
            "Epoch [34/50], Step [200/815], Loss: 3.7635\n",
            "Epoch [34/50], Step [220/815], Loss: 3.5392\n",
            "Epoch [34/50], Step [240/815], Loss: 3.4972\n",
            "Epoch [34/50], Step [260/815], Loss: 3.5922\n",
            "Epoch [34/50], Step [280/815], Loss: 3.5669\n",
            "Epoch [34/50], Step [300/815], Loss: 3.0722\n",
            "Epoch [34/50], Step [320/815], Loss: 3.8086\n",
            "Epoch [34/50], Step [340/815], Loss: 3.6617\n",
            "Epoch [34/50], Step [360/815], Loss: 3.2078\n",
            "Epoch [34/50], Step [380/815], Loss: 3.8447\n",
            "Epoch [34/50], Step [400/815], Loss: 3.6645\n",
            "Epoch [34/50], Step [420/815], Loss: 3.9433\n",
            "Epoch [34/50], Step [440/815], Loss: 3.4493\n",
            "Epoch [34/50], Step [460/815], Loss: 3.7668\n",
            "Epoch [34/50], Step [480/815], Loss: 2.8957\n",
            "Epoch [34/50], Step [500/815], Loss: 2.9688\n",
            "Epoch [34/50], Step [520/815], Loss: 3.7072\n",
            "Epoch [34/50], Step [540/815], Loss: 3.2077\n",
            "Epoch [34/50], Step [560/815], Loss: 3.2946\n",
            "Epoch [34/50], Step [580/815], Loss: 3.6986\n",
            "Epoch [34/50], Step [600/815], Loss: 3.5784\n",
            "Epoch [34/50], Step [620/815], Loss: 3.7020\n",
            "Epoch [34/50], Step [640/815], Loss: 2.7553\n",
            "Epoch [34/50], Step [660/815], Loss: 4.2476\n",
            "Epoch [34/50], Step [680/815], Loss: 3.6859\n",
            "Epoch [34/50], Step [700/815], Loss: 3.4837\n",
            "Epoch [34/50], Step [720/815], Loss: 3.8871\n",
            "Epoch [34/50], Step [740/815], Loss: 3.4354\n",
            "Epoch [34/50], Step [760/815], Loss: 3.5368\n",
            "Epoch [34/50], Step [780/815], Loss: 3.5512\n",
            "Epoch [34/50], Step [800/815], Loss: 3.4670\n",
            "\n",
            "train-loss: 4.2730, train-acc: 36.1984\n",
            "validation loss: 4.3383, validation acc: 24.1512\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 35\n",
            "\n",
            "Epoch [35/50], Step [0/815], Loss: 3.1560\n",
            "Epoch [35/50], Step [20/815], Loss: 3.9490\n",
            "Epoch [35/50], Step [40/815], Loss: 3.7579\n",
            "Epoch [35/50], Step [60/815], Loss: 3.2643\n",
            "Epoch [35/50], Step [80/815], Loss: 3.4846\n",
            "Epoch [35/50], Step [100/815], Loss: 2.7973\n",
            "Epoch [35/50], Step [120/815], Loss: 2.8074\n",
            "Epoch [35/50], Step [140/815], Loss: 3.7088\n",
            "Epoch [35/50], Step [160/815], Loss: 3.1289\n",
            "Epoch [35/50], Step [180/815], Loss: 3.7838\n",
            "Epoch [35/50], Step [200/815], Loss: 3.8573\n",
            "Epoch [35/50], Step [220/815], Loss: 3.2603\n",
            "Epoch [35/50], Step [240/815], Loss: 3.3598\n",
            "Epoch [35/50], Step [260/815], Loss: 3.2315\n",
            "Epoch [35/50], Step [280/815], Loss: 3.5639\n",
            "Epoch [35/50], Step [300/815], Loss: 3.1231\n",
            "Epoch [35/50], Step [320/815], Loss: 3.9373\n",
            "Epoch [35/50], Step [340/815], Loss: 3.3825\n",
            "Epoch [35/50], Step [360/815], Loss: 3.9816\n",
            "Epoch [35/50], Step [380/815], Loss: 3.6503\n",
            "Epoch [35/50], Step [400/815], Loss: 3.7537\n",
            "Epoch [35/50], Step [420/815], Loss: 3.2954\n",
            "Epoch [35/50], Step [440/815], Loss: 3.2432\n",
            "Epoch [35/50], Step [460/815], Loss: 3.1004\n",
            "Epoch [35/50], Step [480/815], Loss: 2.9687\n",
            "Epoch [35/50], Step [500/815], Loss: 2.8844\n",
            "Epoch [35/50], Step [520/815], Loss: 3.8163\n",
            "Epoch [35/50], Step [540/815], Loss: 4.0640\n",
            "Epoch [35/50], Step [560/815], Loss: 3.3771\n",
            "Epoch [35/50], Step [580/815], Loss: 3.4321\n",
            "Epoch [35/50], Step [600/815], Loss: 3.3425\n",
            "Epoch [35/50], Step [620/815], Loss: 3.6692\n",
            "Epoch [35/50], Step [640/815], Loss: 3.9293\n",
            "Epoch [35/50], Step [660/815], Loss: 3.1574\n",
            "Epoch [35/50], Step [680/815], Loss: 3.1117\n",
            "Epoch [35/50], Step [700/815], Loss: 3.4734\n",
            "Epoch [35/50], Step [720/815], Loss: 3.1261\n",
            "Epoch [35/50], Step [740/815], Loss: 3.7776\n",
            "Epoch [35/50], Step [760/815], Loss: 3.4743\n",
            "Epoch [35/50], Step [780/815], Loss: 3.2088\n",
            "Epoch [35/50], Step [800/815], Loss: 3.4598\n",
            "\n",
            "train-loss: 4.2513, train-acc: 36.3581\n",
            "validation loss: 4.3205, validation acc: 25.3700\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 36\n",
            "\n",
            "Epoch [36/50], Step [0/815], Loss: 3.3900\n",
            "Epoch [36/50], Step [20/815], Loss: 3.4238\n",
            "Epoch [36/50], Step [40/815], Loss: 3.7234\n",
            "Epoch [36/50], Step [60/815], Loss: 2.8418\n",
            "Epoch [36/50], Step [80/815], Loss: 3.2272\n",
            "Epoch [36/50], Step [100/815], Loss: 3.1787\n",
            "Epoch [36/50], Step [120/815], Loss: 3.4370\n",
            "Epoch [36/50], Step [140/815], Loss: 3.1070\n",
            "Epoch [36/50], Step [160/815], Loss: 3.5013\n",
            "Epoch [36/50], Step [180/815], Loss: 3.3475\n",
            "Epoch [36/50], Step [200/815], Loss: 3.1296\n",
            "Epoch [36/50], Step [220/815], Loss: 3.2679\n",
            "Epoch [36/50], Step [240/815], Loss: 3.5131\n",
            "Epoch [36/50], Step [260/815], Loss: 3.2041\n",
            "Epoch [36/50], Step [280/815], Loss: 3.6439\n",
            "Epoch [36/50], Step [300/815], Loss: 3.6435\n",
            "Epoch [36/50], Step [320/815], Loss: 3.8117\n",
            "Epoch [36/50], Step [340/815], Loss: 3.7762\n",
            "Epoch [36/50], Step [360/815], Loss: 4.0142\n",
            "Epoch [36/50], Step [380/815], Loss: 3.7759\n",
            "Epoch [36/50], Step [400/815], Loss: 3.4869\n",
            "Epoch [36/50], Step [420/815], Loss: 3.0394\n",
            "Epoch [36/50], Step [440/815], Loss: 3.9274\n",
            "Epoch [36/50], Step [460/815], Loss: 3.3943\n",
            "Epoch [36/50], Step [480/815], Loss: 3.9139\n",
            "Epoch [36/50], Step [500/815], Loss: 3.5902\n",
            "Epoch [36/50], Step [520/815], Loss: 2.6289\n",
            "Epoch [36/50], Step [540/815], Loss: 3.4071\n",
            "Epoch [36/50], Step [560/815], Loss: 4.1045\n",
            "Epoch [36/50], Step [580/815], Loss: 3.9930\n",
            "Epoch [36/50], Step [600/815], Loss: 3.6336\n",
            "Epoch [36/50], Step [620/815], Loss: 3.2724\n",
            "Epoch [36/50], Step [640/815], Loss: 3.3887\n",
            "Epoch [36/50], Step [660/815], Loss: 4.3500\n",
            "Epoch [36/50], Step [680/815], Loss: 3.3025\n",
            "Epoch [36/50], Step [700/815], Loss: 3.2322\n",
            "Epoch [36/50], Step [720/815], Loss: 3.1447\n",
            "Epoch [36/50], Step [740/815], Loss: 3.2151\n",
            "Epoch [36/50], Step [760/815], Loss: 3.2734\n",
            "Epoch [36/50], Step [780/815], Loss: 3.2183\n",
            "Epoch [36/50], Step [800/815], Loss: 2.9595\n",
            "\n",
            "train-loss: 4.2300, train-acc: 37.0948\n",
            "validation loss: 4.3037, validation acc: 24.5492\n",
            "\n",
            "Epoch 37\n",
            "\n",
            "Epoch [37/50], Step [0/815], Loss: 3.1560\n",
            "Epoch [37/50], Step [20/815], Loss: 3.3752\n",
            "Epoch [37/50], Step [40/815], Loss: 3.0397\n",
            "Epoch [37/50], Step [60/815], Loss: 3.3865\n",
            "Epoch [37/50], Step [80/815], Loss: 3.2728\n",
            "Epoch [37/50], Step [100/815], Loss: 3.3508\n",
            "Epoch [37/50], Step [120/815], Loss: 3.5392\n",
            "Epoch [37/50], Step [140/815], Loss: 3.4821\n",
            "Epoch [37/50], Step [160/815], Loss: 3.5947\n",
            "Epoch [37/50], Step [180/815], Loss: 3.5802\n",
            "Epoch [37/50], Step [200/815], Loss: 3.6545\n",
            "Epoch [37/50], Step [220/815], Loss: 3.5880\n",
            "Epoch [37/50], Step [240/815], Loss: 3.1093\n",
            "Epoch [37/50], Step [260/815], Loss: 3.0881\n",
            "Epoch [37/50], Step [280/815], Loss: 3.4775\n",
            "Epoch [37/50], Step [300/815], Loss: 3.2924\n",
            "Epoch [37/50], Step [320/815], Loss: 3.2736\n",
            "Epoch [37/50], Step [340/815], Loss: 3.4315\n",
            "Epoch [37/50], Step [360/815], Loss: 3.4161\n",
            "Epoch [37/50], Step [380/815], Loss: 3.4263\n",
            "Epoch [37/50], Step [400/815], Loss: 3.5410\n",
            "Epoch [37/50], Step [420/815], Loss: 3.6319\n",
            "Epoch [37/50], Step [440/815], Loss: 3.4513\n",
            "Epoch [37/50], Step [460/815], Loss: 3.9015\n",
            "Epoch [37/50], Step [480/815], Loss: 3.3597\n",
            "Epoch [37/50], Step [500/815], Loss: 2.9969\n",
            "Epoch [37/50], Step [520/815], Loss: 3.0623\n",
            "Epoch [37/50], Step [540/815], Loss: 3.1769\n",
            "Epoch [37/50], Step [560/815], Loss: 3.2173\n",
            "Epoch [37/50], Step [580/815], Loss: 3.6838\n",
            "Epoch [37/50], Step [600/815], Loss: 3.2262\n",
            "Epoch [37/50], Step [620/815], Loss: 3.1580\n",
            "Epoch [37/50], Step [640/815], Loss: 3.5638\n",
            "Epoch [37/50], Step [660/815], Loss: 3.6166\n",
            "Epoch [37/50], Step [680/815], Loss: 3.4255\n",
            "Epoch [37/50], Step [700/815], Loss: 3.1949\n",
            "Epoch [37/50], Step [720/815], Loss: 3.3572\n",
            "Epoch [37/50], Step [740/815], Loss: 3.4488\n",
            "Epoch [37/50], Step [760/815], Loss: 3.7871\n",
            "Epoch [37/50], Step [780/815], Loss: 2.9270\n",
            "Epoch [37/50], Step [800/815], Loss: 3.0244\n",
            "\n",
            "train-loss: 4.2089, train-acc: 38.2859\n",
            "validation loss: 4.2867, validation acc: 25.0964\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 38\n",
            "\n",
            "Epoch [38/50], Step [0/815], Loss: 2.9755\n",
            "Epoch [38/50], Step [20/815], Loss: 3.7919\n",
            "Epoch [38/50], Step [40/815], Loss: 3.9157\n",
            "Epoch [38/50], Step [60/815], Loss: 3.7645\n",
            "Epoch [38/50], Step [80/815], Loss: 3.3549\n",
            "Epoch [38/50], Step [100/815], Loss: 3.3112\n",
            "Epoch [38/50], Step [120/815], Loss: 3.3419\n",
            "Epoch [38/50], Step [140/815], Loss: 3.5929\n",
            "Epoch [38/50], Step [160/815], Loss: 3.7203\n",
            "Epoch [38/50], Step [180/815], Loss: 3.1579\n",
            "Epoch [38/50], Step [200/815], Loss: 3.1431\n",
            "Epoch [38/50], Step [220/815], Loss: 3.6616\n",
            "Epoch [38/50], Step [240/815], Loss: 2.8307\n",
            "Epoch [38/50], Step [260/815], Loss: 3.3401\n",
            "Epoch [38/50], Step [280/815], Loss: 3.9339\n",
            "Epoch [38/50], Step [300/815], Loss: 3.1960\n",
            "Epoch [38/50], Step [320/815], Loss: 3.2409\n",
            "Epoch [38/50], Step [340/815], Loss: 3.3720\n",
            "Epoch [38/50], Step [360/815], Loss: 3.3374\n",
            "Epoch [38/50], Step [380/815], Loss: 3.7913\n",
            "Epoch [38/50], Step [400/815], Loss: 3.5318\n",
            "Epoch [38/50], Step [420/815], Loss: 3.5297\n",
            "Epoch [38/50], Step [440/815], Loss: 3.4917\n",
            "Epoch [38/50], Step [460/815], Loss: 3.5099\n",
            "Epoch [38/50], Step [480/815], Loss: 3.6709\n",
            "Epoch [38/50], Step [500/815], Loss: 3.4295\n",
            "Epoch [38/50], Step [520/815], Loss: 3.4427\n",
            "Epoch [38/50], Step [540/815], Loss: 3.5900\n",
            "Epoch [38/50], Step [560/815], Loss: 3.3296\n",
            "Epoch [38/50], Step [580/815], Loss: 3.4913\n",
            "Epoch [38/50], Step [600/815], Loss: 3.3337\n",
            "Epoch [38/50], Step [620/815], Loss: 3.0850\n",
            "Epoch [38/50], Step [640/815], Loss: 3.4998\n",
            "Epoch [38/50], Step [660/815], Loss: 3.3005\n",
            "Epoch [38/50], Step [680/815], Loss: 3.3749\n",
            "Epoch [38/50], Step [700/815], Loss: 3.1626\n",
            "Epoch [38/50], Step [720/815], Loss: 3.1727\n",
            "Epoch [38/50], Step [740/815], Loss: 3.3303\n",
            "Epoch [38/50], Step [760/815], Loss: 3.7344\n",
            "Epoch [38/50], Step [780/815], Loss: 4.1277\n",
            "Epoch [38/50], Step [800/815], Loss: 3.7634\n",
            "\n",
            "train-loss: 4.1884, train-acc: 38.6051\n",
            "validation loss: 4.2702, validation acc: 25.7928\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 39\n",
            "\n",
            "Epoch [39/50], Step [0/815], Loss: 2.9920\n",
            "Epoch [39/50], Step [20/815], Loss: 3.1694\n",
            "Epoch [39/50], Step [40/815], Loss: 3.4597\n",
            "Epoch [39/50], Step [60/815], Loss: 3.6770\n",
            "Epoch [39/50], Step [80/815], Loss: 2.8740\n",
            "Epoch [39/50], Step [100/815], Loss: 2.8005\n",
            "Epoch [39/50], Step [120/815], Loss: 3.5585\n",
            "Epoch [39/50], Step [140/815], Loss: 3.7811\n",
            "Epoch [39/50], Step [160/815], Loss: 3.3487\n",
            "Epoch [39/50], Step [180/815], Loss: 3.4766\n",
            "Epoch [39/50], Step [200/815], Loss: 3.9390\n",
            "Epoch [39/50], Step [220/815], Loss: 3.2667\n",
            "Epoch [39/50], Step [240/815], Loss: 2.8379\n",
            "Epoch [39/50], Step [260/815], Loss: 3.4886\n",
            "Epoch [39/50], Step [280/815], Loss: 3.7442\n",
            "Epoch [39/50], Step [300/815], Loss: 3.3729\n",
            "Epoch [39/50], Step [320/815], Loss: 3.6205\n",
            "Epoch [39/50], Step [340/815], Loss: 2.5814\n",
            "Epoch [39/50], Step [360/815], Loss: 3.5824\n",
            "Epoch [39/50], Step [380/815], Loss: 3.1237\n",
            "Epoch [39/50], Step [400/815], Loss: 3.6653\n",
            "Epoch [39/50], Step [420/815], Loss: 3.6390\n",
            "Epoch [39/50], Step [440/815], Loss: 3.8867\n",
            "Epoch [39/50], Step [460/815], Loss: 3.8202\n",
            "Epoch [39/50], Step [480/815], Loss: 3.6252\n",
            "Epoch [39/50], Step [500/815], Loss: 3.1609\n",
            "Epoch [39/50], Step [520/815], Loss: 3.5409\n",
            "Epoch [39/50], Step [540/815], Loss: 3.3055\n",
            "Epoch [39/50], Step [560/815], Loss: 3.4613\n",
            "Epoch [39/50], Step [580/815], Loss: 3.5278\n",
            "Epoch [39/50], Step [600/815], Loss: 3.3658\n",
            "Epoch [39/50], Step [620/815], Loss: 3.4667\n",
            "Epoch [39/50], Step [640/815], Loss: 3.3765\n",
            "Epoch [39/50], Step [660/815], Loss: 3.4242\n",
            "Epoch [39/50], Step [680/815], Loss: 3.6083\n",
            "Epoch [39/50], Step [700/815], Loss: 3.5793\n",
            "Epoch [39/50], Step [720/815], Loss: 3.7525\n",
            "Epoch [39/50], Step [740/815], Loss: 3.8416\n",
            "Epoch [39/50], Step [760/815], Loss: 3.4669\n",
            "Epoch [39/50], Step [780/815], Loss: 3.1581\n",
            "Epoch [39/50], Step [800/815], Loss: 3.5190\n",
            "\n",
            "train-loss: 4.1681, train-acc: 39.1331\n",
            "validation loss: 4.2539, validation acc: 25.7306\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 40\n",
            "\n",
            "Epoch [40/50], Step [0/815], Loss: 3.4340\n",
            "Epoch [40/50], Step [20/815], Loss: 3.3862\n",
            "Epoch [40/50], Step [40/815], Loss: 3.8889\n",
            "Epoch [40/50], Step [60/815], Loss: 4.2628\n",
            "Epoch [40/50], Step [80/815], Loss: 3.0769\n",
            "Epoch [40/50], Step [100/815], Loss: 3.3323\n",
            "Epoch [40/50], Step [120/815], Loss: 3.8265\n",
            "Epoch [40/50], Step [140/815], Loss: 3.2959\n",
            "Epoch [40/50], Step [160/815], Loss: 3.3855\n",
            "Epoch [40/50], Step [180/815], Loss: 3.2786\n",
            "Epoch [40/50], Step [200/815], Loss: 3.2402\n",
            "Epoch [40/50], Step [220/815], Loss: 3.0081\n",
            "Epoch [40/50], Step [240/815], Loss: 3.7234\n",
            "Epoch [40/50], Step [260/815], Loss: 3.1767\n",
            "Epoch [40/50], Step [280/815], Loss: 2.6157\n",
            "Epoch [40/50], Step [300/815], Loss: 3.3239\n",
            "Epoch [40/50], Step [320/815], Loss: 3.2866\n",
            "Epoch [40/50], Step [340/815], Loss: 3.4252\n",
            "Epoch [40/50], Step [360/815], Loss: 2.9600\n",
            "Epoch [40/50], Step [380/815], Loss: 3.7431\n",
            "Epoch [40/50], Step [400/815], Loss: 3.4216\n",
            "Epoch [40/50], Step [420/815], Loss: 2.7248\n",
            "Epoch [40/50], Step [440/815], Loss: 2.9747\n",
            "Epoch [40/50], Step [460/815], Loss: 3.0912\n",
            "Epoch [40/50], Step [480/815], Loss: 3.4592\n",
            "Epoch [40/50], Step [500/815], Loss: 3.5869\n",
            "Epoch [40/50], Step [520/815], Loss: 3.3687\n",
            "Epoch [40/50], Step [540/815], Loss: 3.1392\n",
            "Epoch [40/50], Step [560/815], Loss: 3.8752\n",
            "Epoch [40/50], Step [580/815], Loss: 3.3039\n",
            "Epoch [40/50], Step [600/815], Loss: 3.3611\n",
            "Epoch [40/50], Step [620/815], Loss: 3.5180\n",
            "Epoch [40/50], Step [640/815], Loss: 3.4162\n",
            "Epoch [40/50], Step [660/815], Loss: 3.0556\n",
            "Epoch [40/50], Step [680/815], Loss: 3.4363\n",
            "Epoch [40/50], Step [700/815], Loss: 3.2435\n",
            "Epoch [40/50], Step [720/815], Loss: 3.3788\n",
            "Epoch [40/50], Step [740/815], Loss: 3.7924\n",
            "Epoch [40/50], Step [760/815], Loss: 3.1980\n",
            "Epoch [40/50], Step [780/815], Loss: 3.3188\n",
            "Epoch [40/50], Step [800/815], Loss: 2.5713\n",
            "\n",
            "train-loss: 4.1481, train-acc: 39.3787\n",
            "validation loss: 4.2378, validation acc: 26.3027\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 41\n",
            "\n",
            "Epoch [41/50], Step [0/815], Loss: 3.4374\n",
            "Epoch [41/50], Step [20/815], Loss: 3.3480\n",
            "Epoch [41/50], Step [40/815], Loss: 3.1770\n",
            "Epoch [41/50], Step [60/815], Loss: 3.1134\n",
            "Epoch [41/50], Step [80/815], Loss: 3.2199\n",
            "Epoch [41/50], Step [100/815], Loss: 3.6305\n",
            "Epoch [41/50], Step [120/815], Loss: 3.2552\n",
            "Epoch [41/50], Step [140/815], Loss: 3.1418\n",
            "Epoch [41/50], Step [160/815], Loss: 3.5545\n",
            "Epoch [41/50], Step [180/815], Loss: 3.8422\n",
            "Epoch [41/50], Step [200/815], Loss: 3.4927\n",
            "Epoch [41/50], Step [220/815], Loss: 3.5844\n",
            "Epoch [41/50], Step [240/815], Loss: 3.0698\n",
            "Epoch [41/50], Step [260/815], Loss: 3.2770\n",
            "Epoch [41/50], Step [280/815], Loss: 3.4883\n",
            "Epoch [41/50], Step [300/815], Loss: 3.3392\n",
            "Epoch [41/50], Step [320/815], Loss: 3.3256\n",
            "Epoch [41/50], Step [340/815], Loss: 3.6560\n",
            "Epoch [41/50], Step [360/815], Loss: 3.5290\n",
            "Epoch [41/50], Step [380/815], Loss: 3.2450\n",
            "Epoch [41/50], Step [400/815], Loss: 3.4019\n",
            "Epoch [41/50], Step [420/815], Loss: 2.7616\n",
            "Epoch [41/50], Step [440/815], Loss: 3.1340\n",
            "Epoch [41/50], Step [460/815], Loss: 3.1728\n",
            "Epoch [41/50], Step [480/815], Loss: 3.5296\n",
            "Epoch [41/50], Step [500/815], Loss: 3.6856\n",
            "Epoch [41/50], Step [520/815], Loss: 4.0094\n",
            "Epoch [41/50], Step [540/815], Loss: 2.8741\n",
            "Epoch [41/50], Step [560/815], Loss: 3.0495\n",
            "Epoch [41/50], Step [580/815], Loss: 3.2027\n",
            "Epoch [41/50], Step [600/815], Loss: 3.0420\n",
            "Epoch [41/50], Step [620/815], Loss: 3.4905\n",
            "Epoch [41/50], Step [640/815], Loss: 3.0653\n",
            "Epoch [41/50], Step [660/815], Loss: 3.2251\n",
            "Epoch [41/50], Step [680/815], Loss: 3.8549\n",
            "Epoch [41/50], Step [700/815], Loss: 3.3452\n",
            "Epoch [41/50], Step [720/815], Loss: 3.6321\n",
            "Epoch [41/50], Step [740/815], Loss: 3.4719\n",
            "Epoch [41/50], Step [760/815], Loss: 3.2770\n",
            "Epoch [41/50], Step [780/815], Loss: 3.0543\n",
            "Epoch [41/50], Step [800/815], Loss: 3.4256\n",
            "\n",
            "train-loss: 4.1286, train-acc: 39.9190\n",
            "validation loss: 4.2223, validation acc: 26.3400\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 42\n",
            "\n",
            "Epoch [42/50], Step [0/815], Loss: 3.2464\n",
            "Epoch [42/50], Step [20/815], Loss: 3.5307\n",
            "Epoch [42/50], Step [40/815], Loss: 3.1185\n",
            "Epoch [42/50], Step [60/815], Loss: 3.7341\n",
            "Epoch [42/50], Step [80/815], Loss: 3.4244\n",
            "Epoch [42/50], Step [100/815], Loss: 3.5015\n",
            "Epoch [42/50], Step [120/815], Loss: 3.5309\n",
            "Epoch [42/50], Step [140/815], Loss: 3.0187\n",
            "Epoch [42/50], Step [160/815], Loss: 3.5979\n",
            "Epoch [42/50], Step [180/815], Loss: 2.7178\n",
            "Epoch [42/50], Step [200/815], Loss: 2.9226\n",
            "Epoch [42/50], Step [220/815], Loss: 3.1579\n",
            "Epoch [42/50], Step [240/815], Loss: 3.4007\n",
            "Epoch [42/50], Step [260/815], Loss: 3.2711\n",
            "Epoch [42/50], Step [280/815], Loss: 3.0296\n",
            "Epoch [42/50], Step [300/815], Loss: 3.1331\n",
            "Epoch [42/50], Step [320/815], Loss: 3.7755\n",
            "Epoch [42/50], Step [340/815], Loss: 3.4211\n",
            "Epoch [42/50], Step [360/815], Loss: 3.5082\n",
            "Epoch [42/50], Step [380/815], Loss: 3.4823\n",
            "Epoch [42/50], Step [400/815], Loss: 2.9206\n",
            "Epoch [42/50], Step [420/815], Loss: 2.8518\n",
            "Epoch [42/50], Step [440/815], Loss: 3.2856\n",
            "Epoch [42/50], Step [460/815], Loss: 2.7119\n",
            "Epoch [42/50], Step [480/815], Loss: 3.1896\n",
            "Epoch [42/50], Step [500/815], Loss: 3.6218\n",
            "Epoch [42/50], Step [520/815], Loss: 3.6084\n",
            "Epoch [42/50], Step [540/815], Loss: 3.3729\n",
            "Epoch [42/50], Step [560/815], Loss: 3.6752\n",
            "Epoch [42/50], Step [580/815], Loss: 3.6246\n",
            "Epoch [42/50], Step [600/815], Loss: 3.1462\n",
            "Epoch [42/50], Step [620/815], Loss: 3.2839\n",
            "Epoch [42/50], Step [640/815], Loss: 3.2395\n",
            "Epoch [42/50], Step [660/815], Loss: 3.6405\n",
            "Epoch [42/50], Step [680/815], Loss: 3.3095\n",
            "Epoch [42/50], Step [700/815], Loss: 3.3595\n",
            "Epoch [42/50], Step [720/815], Loss: 2.8220\n",
            "Epoch [42/50], Step [740/815], Loss: 3.1101\n",
            "Epoch [42/50], Step [760/815], Loss: 3.3020\n",
            "Epoch [42/50], Step [780/815], Loss: 2.7458\n",
            "Epoch [42/50], Step [800/815], Loss: 3.4475\n",
            "\n",
            "train-loss: 4.1093, train-acc: 39.3296\n",
            "validation loss: 4.2072, validation acc: 26.1410\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 43\n",
            "\n",
            "Epoch [43/50], Step [0/815], Loss: 3.7330\n",
            "Epoch [43/50], Step [20/815], Loss: 2.8399\n",
            "Epoch [43/50], Step [40/815], Loss: 3.7081\n",
            "Epoch [43/50], Step [60/815], Loss: 3.4101\n",
            "Epoch [43/50], Step [80/815], Loss: 3.4629\n",
            "Epoch [43/50], Step [100/815], Loss: 3.2522\n",
            "Epoch [43/50], Step [120/815], Loss: 2.9831\n",
            "Epoch [43/50], Step [140/815], Loss: 3.2903\n",
            "Epoch [43/50], Step [160/815], Loss: 3.1963\n",
            "Epoch [43/50], Step [180/815], Loss: 3.1989\n",
            "Epoch [43/50], Step [200/815], Loss: 3.5495\n",
            "Epoch [43/50], Step [220/815], Loss: 2.8629\n",
            "Epoch [43/50], Step [240/815], Loss: 3.1783\n",
            "Epoch [43/50], Step [260/815], Loss: 3.2864\n",
            "Epoch [43/50], Step [280/815], Loss: 2.8647\n",
            "Epoch [43/50], Step [300/815], Loss: 3.2698\n",
            "Epoch [43/50], Step [320/815], Loss: 3.4723\n",
            "Epoch [43/50], Step [340/815], Loss: 2.7807\n",
            "Epoch [43/50], Step [360/815], Loss: 3.5224\n",
            "Epoch [43/50], Step [380/815], Loss: 3.1598\n",
            "Epoch [43/50], Step [400/815], Loss: 3.5208\n",
            "Epoch [43/50], Step [420/815], Loss: 3.4962\n",
            "Epoch [43/50], Step [440/815], Loss: 2.9251\n",
            "Epoch [43/50], Step [460/815], Loss: 3.3872\n",
            "Epoch [43/50], Step [480/815], Loss: 3.4251\n",
            "Epoch [43/50], Step [500/815], Loss: 3.4773\n",
            "Epoch [43/50], Step [520/815], Loss: 3.2560\n",
            "Epoch [43/50], Step [540/815], Loss: 3.5070\n",
            "Epoch [43/50], Step [560/815], Loss: 3.4008\n",
            "Epoch [43/50], Step [580/815], Loss: 3.3607\n",
            "Epoch [43/50], Step [600/815], Loss: 3.2693\n",
            "Epoch [43/50], Step [620/815], Loss: 3.6067\n",
            "Epoch [43/50], Step [640/815], Loss: 3.4424\n",
            "Epoch [43/50], Step [660/815], Loss: 3.2013\n",
            "Epoch [43/50], Step [680/815], Loss: 3.3073\n",
            "Epoch [43/50], Step [700/815], Loss: 3.8058\n",
            "Epoch [43/50], Step [720/815], Loss: 3.2732\n",
            "Epoch [43/50], Step [740/815], Loss: 3.5626\n",
            "Epoch [43/50], Step [760/815], Loss: 3.7709\n",
            "Epoch [43/50], Step [780/815], Loss: 3.4226\n",
            "Epoch [43/50], Step [800/815], Loss: 3.7307\n",
            "\n",
            "train-loss: 4.0902, train-acc: 40.6189\n",
            "validation loss: 4.1923, validation acc: 26.1410\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 44\n",
            "\n",
            "Epoch [44/50], Step [0/815], Loss: 2.8520\n",
            "Epoch [44/50], Step [20/815], Loss: 2.8215\n",
            "Epoch [44/50], Step [40/815], Loss: 3.4336\n",
            "Epoch [44/50], Step [60/815], Loss: 3.5455\n",
            "Epoch [44/50], Step [80/815], Loss: 2.7983\n",
            "Epoch [44/50], Step [100/815], Loss: 3.3518\n",
            "Epoch [44/50], Step [120/815], Loss: 3.0274\n",
            "Epoch [44/50], Step [140/815], Loss: 3.0258\n",
            "Epoch [44/50], Step [160/815], Loss: 3.6014\n",
            "Epoch [44/50], Step [180/815], Loss: 3.2407\n",
            "Epoch [44/50], Step [200/815], Loss: 3.0825\n",
            "Epoch [44/50], Step [220/815], Loss: 3.3960\n",
            "Epoch [44/50], Step [240/815], Loss: 3.5614\n",
            "Epoch [44/50], Step [260/815], Loss: 3.8643\n",
            "Epoch [44/50], Step [280/815], Loss: 3.1668\n",
            "Epoch [44/50], Step [300/815], Loss: 3.5656\n",
            "Epoch [44/50], Step [320/815], Loss: 3.4430\n",
            "Epoch [44/50], Step [340/815], Loss: 2.9503\n",
            "Epoch [44/50], Step [360/815], Loss: 3.3451\n",
            "Epoch [44/50], Step [380/815], Loss: 3.1226\n",
            "Epoch [44/50], Step [400/815], Loss: 3.8691\n",
            "Epoch [44/50], Step [420/815], Loss: 3.2495\n",
            "Epoch [44/50], Step [440/815], Loss: 2.9849\n",
            "Epoch [44/50], Step [460/815], Loss: 3.1473\n",
            "Epoch [44/50], Step [480/815], Loss: 3.0304\n",
            "Epoch [44/50], Step [500/815], Loss: 3.1243\n",
            "Epoch [44/50], Step [520/815], Loss: 3.6785\n",
            "Epoch [44/50], Step [540/815], Loss: 3.1630\n",
            "Epoch [44/50], Step [560/815], Loss: 3.3760\n",
            "Epoch [44/50], Step [580/815], Loss: 3.6158\n",
            "Epoch [44/50], Step [600/815], Loss: 3.0112\n",
            "Epoch [44/50], Step [620/815], Loss: 3.8161\n",
            "Epoch [44/50], Step [640/815], Loss: 3.0426\n",
            "Epoch [44/50], Step [660/815], Loss: 3.7128\n",
            "Epoch [44/50], Step [680/815], Loss: 3.2314\n",
            "Epoch [44/50], Step [700/815], Loss: 3.1837\n",
            "Epoch [44/50], Step [720/815], Loss: 3.1149\n",
            "Epoch [44/50], Step [740/815], Loss: 3.1631\n",
            "Epoch [44/50], Step [760/815], Loss: 3.4343\n",
            "Epoch [44/50], Step [780/815], Loss: 2.8366\n",
            "Epoch [44/50], Step [800/815], Loss: 3.3360\n",
            "\n",
            "train-loss: 4.0715, train-acc: 40.9627\n",
            "validation loss: 4.1779, validation acc: 26.7504\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 45\n",
            "\n",
            "Epoch [45/50], Step [0/815], Loss: 3.0655\n",
            "Epoch [45/50], Step [20/815], Loss: 3.0529\n",
            "Epoch [45/50], Step [40/815], Loss: 3.4720\n",
            "Epoch [45/50], Step [60/815], Loss: 2.2878\n",
            "Epoch [45/50], Step [80/815], Loss: 2.8751\n",
            "Epoch [45/50], Step [100/815], Loss: 3.2177\n",
            "Epoch [45/50], Step [120/815], Loss: 3.1421\n",
            "Epoch [45/50], Step [140/815], Loss: 3.0958\n",
            "Epoch [45/50], Step [160/815], Loss: 2.9636\n",
            "Epoch [45/50], Step [180/815], Loss: 3.0724\n",
            "Epoch [45/50], Step [200/815], Loss: 3.5315\n",
            "Epoch [45/50], Step [220/815], Loss: 2.6995\n",
            "Epoch [45/50], Step [240/815], Loss: 3.2415\n",
            "Epoch [45/50], Step [260/815], Loss: 3.1486\n",
            "Epoch [45/50], Step [280/815], Loss: 2.9781\n",
            "Epoch [45/50], Step [300/815], Loss: 3.1533\n",
            "Epoch [45/50], Step [320/815], Loss: 3.3445\n",
            "Epoch [45/50], Step [340/815], Loss: 2.9503\n",
            "Epoch [45/50], Step [360/815], Loss: 3.3806\n",
            "Epoch [45/50], Step [380/815], Loss: 3.7475\n",
            "Epoch [45/50], Step [400/815], Loss: 3.1809\n",
            "Epoch [45/50], Step [420/815], Loss: 3.4880\n",
            "Epoch [45/50], Step [440/815], Loss: 3.4916\n",
            "Epoch [45/50], Step [460/815], Loss: 3.3070\n",
            "Epoch [45/50], Step [480/815], Loss: 2.9423\n",
            "Epoch [45/50], Step [500/815], Loss: 2.8739\n",
            "Epoch [45/50], Step [520/815], Loss: 3.0683\n",
            "Epoch [45/50], Step [540/815], Loss: 3.5110\n",
            "Epoch [45/50], Step [560/815], Loss: 2.8358\n",
            "Epoch [45/50], Step [580/815], Loss: 3.3184\n",
            "Epoch [45/50], Step [600/815], Loss: 2.8427\n",
            "Epoch [45/50], Step [620/815], Loss: 3.6586\n",
            "Epoch [45/50], Step [640/815], Loss: 3.3184\n",
            "Epoch [45/50], Step [660/815], Loss: 3.8734\n",
            "Epoch [45/50], Step [680/815], Loss: 3.3657\n",
            "Epoch [45/50], Step [700/815], Loss: 3.5565\n",
            "Epoch [45/50], Step [720/815], Loss: 3.4390\n",
            "Epoch [45/50], Step [740/815], Loss: 2.8615\n",
            "Epoch [45/50], Step [760/815], Loss: 3.9779\n",
            "Epoch [45/50], Step [780/815], Loss: 3.1307\n",
            "Epoch [45/50], Step [800/815], Loss: 3.0968\n",
            "\n",
            "train-loss: 4.0532, train-acc: 41.1837\n",
            "validation loss: 4.1633, validation acc: 27.2479\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 46\n",
            "\n",
            "Epoch [46/50], Step [0/815], Loss: 2.7573\n",
            "Epoch [46/50], Step [20/815], Loss: 2.9673\n",
            "Epoch [46/50], Step [40/815], Loss: 2.7932\n",
            "Epoch [46/50], Step [60/815], Loss: 3.5542\n",
            "Epoch [46/50], Step [80/815], Loss: 3.1843\n",
            "Epoch [46/50], Step [100/815], Loss: 3.3720\n",
            "Epoch [46/50], Step [120/815], Loss: 2.6790\n",
            "Epoch [46/50], Step [140/815], Loss: 3.1585\n",
            "Epoch [46/50], Step [160/815], Loss: 2.6740\n",
            "Epoch [46/50], Step [180/815], Loss: 3.4185\n",
            "Epoch [46/50], Step [200/815], Loss: 3.3689\n",
            "Epoch [46/50], Step [220/815], Loss: 3.2679\n",
            "Epoch [46/50], Step [240/815], Loss: 3.7095\n",
            "Epoch [46/50], Step [260/815], Loss: 3.5774\n",
            "Epoch [46/50], Step [280/815], Loss: 3.3242\n",
            "Epoch [46/50], Step [300/815], Loss: 3.5737\n",
            "Epoch [46/50], Step [320/815], Loss: 3.6659\n",
            "Epoch [46/50], Step [340/815], Loss: 3.0921\n",
            "Epoch [46/50], Step [360/815], Loss: 3.0121\n",
            "Epoch [46/50], Step [380/815], Loss: 2.7276\n",
            "Epoch [46/50], Step [400/815], Loss: 3.7449\n",
            "Epoch [46/50], Step [420/815], Loss: 3.4980\n",
            "Epoch [46/50], Step [440/815], Loss: 3.3469\n",
            "Epoch [46/50], Step [460/815], Loss: 3.3461\n",
            "Epoch [46/50], Step [480/815], Loss: 3.5280\n",
            "Epoch [46/50], Step [500/815], Loss: 3.0452\n",
            "Epoch [46/50], Step [520/815], Loss: 3.0202\n",
            "Epoch [46/50], Step [540/815], Loss: 3.4564\n",
            "Epoch [46/50], Step [560/815], Loss: 3.3944\n",
            "Epoch [46/50], Step [580/815], Loss: 3.3981\n",
            "Epoch [46/50], Step [600/815], Loss: 2.9825\n",
            "Epoch [46/50], Step [620/815], Loss: 3.7771\n",
            "Epoch [46/50], Step [640/815], Loss: 2.8258\n",
            "Epoch [46/50], Step [660/815], Loss: 2.9466\n",
            "Epoch [46/50], Step [680/815], Loss: 3.3538\n",
            "Epoch [46/50], Step [700/815], Loss: 2.6837\n",
            "Epoch [46/50], Step [720/815], Loss: 3.3441\n",
            "Epoch [46/50], Step [740/815], Loss: 3.0543\n",
            "Epoch [46/50], Step [760/815], Loss: 3.3660\n",
            "Epoch [46/50], Step [780/815], Loss: 2.7908\n",
            "Epoch [46/50], Step [800/815], Loss: 3.3817\n",
            "\n",
            "train-loss: 4.0351, train-acc: 41.4661\n",
            "validation loss: 4.1493, validation acc: 27.5339\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 47\n",
            "\n",
            "Epoch [47/50], Step [0/815], Loss: 3.4601\n",
            "Epoch [47/50], Step [20/815], Loss: 4.0840\n",
            "Epoch [47/50], Step [40/815], Loss: 3.1610\n",
            "Epoch [47/50], Step [60/815], Loss: 3.0467\n",
            "Epoch [47/50], Step [80/815], Loss: 3.6021\n",
            "Epoch [47/50], Step [100/815], Loss: 3.6811\n",
            "Epoch [47/50], Step [120/815], Loss: 2.2927\n",
            "Epoch [47/50], Step [140/815], Loss: 2.9665\n",
            "Epoch [47/50], Step [160/815], Loss: 3.5775\n",
            "Epoch [47/50], Step [180/815], Loss: 3.1199\n",
            "Epoch [47/50], Step [200/815], Loss: 2.8728\n",
            "Epoch [47/50], Step [220/815], Loss: 3.0985\n",
            "Epoch [47/50], Step [240/815], Loss: 2.9453\n",
            "Epoch [47/50], Step [260/815], Loss: 3.2459\n",
            "Epoch [47/50], Step [280/815], Loss: 3.0697\n",
            "Epoch [47/50], Step [300/815], Loss: 2.9420\n",
            "Epoch [47/50], Step [320/815], Loss: 3.2025\n",
            "Epoch [47/50], Step [340/815], Loss: 3.3091\n",
            "Epoch [47/50], Step [360/815], Loss: 2.8469\n",
            "Epoch [47/50], Step [380/815], Loss: 3.2860\n",
            "Epoch [47/50], Step [400/815], Loss: 2.5369\n",
            "Epoch [47/50], Step [420/815], Loss: 3.3602\n",
            "Epoch [47/50], Step [440/815], Loss: 2.9598\n",
            "Epoch [47/50], Step [460/815], Loss: 2.5136\n",
            "Epoch [47/50], Step [480/815], Loss: 3.3199\n",
            "Epoch [47/50], Step [500/815], Loss: 3.4007\n",
            "Epoch [47/50], Step [520/815], Loss: 3.0751\n",
            "Epoch [47/50], Step [540/815], Loss: 3.6251\n",
            "Epoch [47/50], Step [560/815], Loss: 3.0336\n",
            "Epoch [47/50], Step [580/815], Loss: 3.0061\n",
            "Epoch [47/50], Step [600/815], Loss: 3.4215\n",
            "Epoch [47/50], Step [620/815], Loss: 3.9584\n",
            "Epoch [47/50], Step [640/815], Loss: 3.2493\n",
            "Epoch [47/50], Step [660/815], Loss: 3.5354\n",
            "Epoch [47/50], Step [680/815], Loss: 3.1640\n",
            "Epoch [47/50], Step [700/815], Loss: 3.0296\n",
            "Epoch [47/50], Step [720/815], Loss: 3.0816\n",
            "Epoch [47/50], Step [740/815], Loss: 3.3557\n",
            "Epoch [47/50], Step [760/815], Loss: 3.4458\n",
            "Epoch [47/50], Step [780/815], Loss: 3.1899\n",
            "Epoch [47/50], Step [800/815], Loss: 3.5360\n",
            "\n",
            "train-loss: 4.0170, train-acc: 42.9764\n",
            "validation loss: 4.1354, validation acc: 27.2603\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 48\n",
            "\n",
            "Epoch [48/50], Step [0/815], Loss: 3.0450\n",
            "Epoch [48/50], Step [20/815], Loss: 3.4609\n",
            "Epoch [48/50], Step [40/815], Loss: 3.5695\n",
            "Epoch [48/50], Step [60/815], Loss: 2.8778\n",
            "Epoch [48/50], Step [80/815], Loss: 3.7648\n",
            "Epoch [48/50], Step [100/815], Loss: 3.5971\n",
            "Epoch [48/50], Step [120/815], Loss: 3.2843\n",
            "Epoch [48/50], Step [140/815], Loss: 3.3656\n",
            "Epoch [48/50], Step [160/815], Loss: 3.0745\n",
            "Epoch [48/50], Step [180/815], Loss: 2.9948\n",
            "Epoch [48/50], Step [200/815], Loss: 3.4112\n",
            "Epoch [48/50], Step [220/815], Loss: 2.7537\n",
            "Epoch [48/50], Step [240/815], Loss: 3.3543\n",
            "Epoch [48/50], Step [260/815], Loss: 2.8716\n",
            "Epoch [48/50], Step [280/815], Loss: 3.3154\n",
            "Epoch [48/50], Step [300/815], Loss: 3.5375\n",
            "Epoch [48/50], Step [320/815], Loss: 2.5177\n",
            "Epoch [48/50], Step [340/815], Loss: 3.3948\n",
            "Epoch [48/50], Step [360/815], Loss: 2.7810\n",
            "Epoch [48/50], Step [380/815], Loss: 3.1533\n",
            "Epoch [48/50], Step [400/815], Loss: 3.5339\n",
            "Epoch [48/50], Step [420/815], Loss: 3.5302\n",
            "Epoch [48/50], Step [440/815], Loss: 2.3786\n",
            "Epoch [48/50], Step [460/815], Loss: 3.4533\n",
            "Epoch [48/50], Step [480/815], Loss: 3.0011\n",
            "Epoch [48/50], Step [500/815], Loss: 3.0230\n",
            "Epoch [48/50], Step [520/815], Loss: 2.6355\n",
            "Epoch [48/50], Step [540/815], Loss: 3.3239\n",
            "Epoch [48/50], Step [560/815], Loss: 3.2544\n",
            "Epoch [48/50], Step [580/815], Loss: 3.0257\n",
            "Epoch [48/50], Step [600/815], Loss: 3.7221\n",
            "Epoch [48/50], Step [620/815], Loss: 2.7513\n",
            "Epoch [48/50], Step [640/815], Loss: 3.0979\n",
            "Epoch [48/50], Step [660/815], Loss: 3.6026\n",
            "Epoch [48/50], Step [680/815], Loss: 3.4049\n",
            "Epoch [48/50], Step [700/815], Loss: 3.2996\n",
            "Epoch [48/50], Step [720/815], Loss: 3.6695\n",
            "Epoch [48/50], Step [740/815], Loss: 3.4223\n",
            "Epoch [48/50], Step [760/815], Loss: 2.5020\n",
            "Epoch [48/50], Step [780/815], Loss: 3.3997\n",
            "Epoch [48/50], Step [800/815], Loss: 2.9410\n",
            "\n",
            "train-loss: 3.9995, train-acc: 42.5221\n",
            "validation loss: 4.1219, validation acc: 27.4717\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 49\n",
            "\n",
            "Epoch [49/50], Step [0/815], Loss: 2.7213\n",
            "Epoch [49/50], Step [20/815], Loss: 3.7498\n",
            "Epoch [49/50], Step [40/815], Loss: 2.9946\n",
            "Epoch [49/50], Step [60/815], Loss: 3.6310\n",
            "Epoch [49/50], Step [80/815], Loss: 3.4212\n",
            "Epoch [49/50], Step [100/815], Loss: 3.2298\n",
            "Epoch [49/50], Step [120/815], Loss: 2.9859\n",
            "Epoch [49/50], Step [140/815], Loss: 3.5525\n",
            "Epoch [49/50], Step [160/815], Loss: 2.3586\n",
            "Epoch [49/50], Step [180/815], Loss: 2.7653\n",
            "Epoch [49/50], Step [200/815], Loss: 3.2675\n",
            "Epoch [49/50], Step [220/815], Loss: 3.5479\n",
            "Epoch [49/50], Step [240/815], Loss: 3.4510\n",
            "Epoch [49/50], Step [260/815], Loss: 3.1863\n",
            "Epoch [49/50], Step [280/815], Loss: 3.3703\n",
            "Epoch [49/50], Step [300/815], Loss: 3.3109\n",
            "Epoch [49/50], Step [320/815], Loss: 3.1381\n",
            "Epoch [49/50], Step [340/815], Loss: 2.9232\n",
            "Epoch [49/50], Step [360/815], Loss: 2.8200\n",
            "Epoch [49/50], Step [380/815], Loss: 2.8370\n",
            "Epoch [49/50], Step [400/815], Loss: 3.0580\n",
            "Epoch [49/50], Step [420/815], Loss: 2.8881\n",
            "Epoch [49/50], Step [440/815], Loss: 3.5015\n",
            "Epoch [49/50], Step [460/815], Loss: 2.6617\n",
            "Epoch [49/50], Step [480/815], Loss: 3.3247\n",
            "Epoch [49/50], Step [500/815], Loss: 2.7672\n",
            "Epoch [49/50], Step [520/815], Loss: 3.3957\n",
            "Epoch [49/50], Step [540/815], Loss: 3.4632\n",
            "Epoch [49/50], Step [560/815], Loss: 2.9076\n",
            "Epoch [49/50], Step [580/815], Loss: 3.2943\n",
            "Epoch [49/50], Step [600/815], Loss: 3.0692\n",
            "Epoch [49/50], Step [620/815], Loss: 2.4941\n",
            "Epoch [49/50], Step [640/815], Loss: 3.3854\n",
            "Epoch [49/50], Step [660/815], Loss: 2.7910\n",
            "Epoch [49/50], Step [680/815], Loss: 2.8294\n",
            "Epoch [49/50], Step [700/815], Loss: 2.8817\n",
            "Epoch [49/50], Step [720/815], Loss: 2.5992\n",
            "Epoch [49/50], Step [740/815], Loss: 3.5269\n",
            "Epoch [49/50], Step [760/815], Loss: 3.1686\n",
            "Epoch [49/50], Step [780/815], Loss: 2.6482\n",
            "Epoch [49/50], Step [800/815], Loss: 3.5962\n",
            "\n",
            "train-loss: 3.9820, train-acc: 42.8045\n",
            "validation loss: 4.1085, validation acc: 27.8572\n",
            "\n",
            "Improvement-Detected, save-model\n",
            "Epoch 50\n",
            "\n",
            "Epoch [50/50], Step [0/815], Loss: 3.0974\n",
            "Epoch [50/50], Step [20/815], Loss: 3.3919\n",
            "Epoch [50/50], Step [40/815], Loss: 3.4101\n",
            "Epoch [50/50], Step [60/815], Loss: 4.1255\n",
            "Epoch [50/50], Step [80/815], Loss: 2.9511\n",
            "Epoch [50/50], Step [100/815], Loss: 3.3128\n",
            "Epoch [50/50], Step [120/815], Loss: 2.9040\n",
            "Epoch [50/50], Step [140/815], Loss: 3.0280\n",
            "Epoch [50/50], Step [160/815], Loss: 3.3682\n",
            "Epoch [50/50], Step [180/815], Loss: 3.7246\n",
            "Epoch [50/50], Step [200/815], Loss: 2.4531\n",
            "Epoch [50/50], Step [220/815], Loss: 2.6511\n",
            "Epoch [50/50], Step [240/815], Loss: 3.3703\n",
            "Epoch [50/50], Step [260/815], Loss: 2.9075\n",
            "Epoch [50/50], Step [280/815], Loss: 3.3239\n",
            "Epoch [50/50], Step [300/815], Loss: 2.6478\n",
            "Epoch [50/50], Step [320/815], Loss: 2.9206\n",
            "Epoch [50/50], Step [340/815], Loss: 2.9251\n",
            "Epoch [50/50], Step [360/815], Loss: 3.1912\n",
            "Epoch [50/50], Step [380/815], Loss: 3.0260\n",
            "Epoch [50/50], Step [400/815], Loss: 2.8683\n",
            "Epoch [50/50], Step [420/815], Loss: 3.9875\n",
            "Epoch [50/50], Step [440/815], Loss: 2.9656\n",
            "Epoch [50/50], Step [460/815], Loss: 3.1935\n",
            "Epoch [50/50], Step [480/815], Loss: 3.2944\n",
            "Epoch [50/50], Step [500/815], Loss: 3.3120\n",
            "Epoch [50/50], Step [520/815], Loss: 3.4211\n",
            "Epoch [50/50], Step [540/815], Loss: 2.7613\n",
            "Epoch [50/50], Step [560/815], Loss: 2.7948\n",
            "Epoch [50/50], Step [580/815], Loss: 2.7997\n",
            "Epoch [50/50], Step [600/815], Loss: 2.8213\n",
            "Epoch [50/50], Step [620/815], Loss: 3.5311\n",
            "Epoch [50/50], Step [640/815], Loss: 2.7626\n",
            "Epoch [50/50], Step [660/815], Loss: 3.7288\n",
            "Epoch [50/50], Step [680/815], Loss: 3.2671\n",
            "Epoch [50/50], Step [700/815], Loss: 2.5295\n",
            "Epoch [50/50], Step [720/815], Loss: 3.7107\n",
            "Epoch [50/50], Step [740/815], Loss: 2.6979\n",
            "Epoch [50/50], Step [760/815], Loss: 3.2823\n",
            "Epoch [50/50], Step [780/815], Loss: 3.2075\n",
            "Epoch [50/50], Step [800/815], Loss: 3.7759\n",
            "\n",
            "train-loss: 3.9649, train-acc: 43.4676\n",
            "validation loss: 4.0953, validation acc: 28.3547\n",
            "\n",
            "Improvement-Detected, save-model\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 30\n",
        "EPOCHS = 50\n",
        "print_every = 10\n",
        "valid_loss_min = np.Inf\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total=0\n",
        "    print(f'Epoch {epoch}\\n')\n",
        "    for batch_idx, (data_, target_) in enumerate(train_loader):\n",
        "        data_, target_ = data_.to(device), target_.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = resnet(data_)\n",
        "        loss = criterion(outputs, target_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _,pred = torch.max(outputs, dim=1)\n",
        "        correct += torch.sum(pred==target_).item()\n",
        "        total += target_.size(0)\n",
        "        if (batch_idx) % 20 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch, EPOCHS, batch_idx, total_step, loss.item()))\n",
        "    train_acc.append(100 * correct / total)\n",
        "    train_loss.append(running_loss/total_step)\n",
        "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
        "    batch_loss = 0\n",
        "    total_t=0\n",
        "    correct_t=0\n",
        "    with torch.no_grad():\n",
        "        resnet.eval()\n",
        "        for data_t, target_t in (test_loader):\n",
        "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
        "            outputs_t = resnet(data_t)\n",
        "            loss_t = criterion(outputs_t, target_t)\n",
        "            batch_loss += loss_t.item()\n",
        "            _,pred_t = torch.max(outputs_t, dim=1)\n",
        "            correct_t += torch.sum(pred_t==target_t).item()\n",
        "            total_t += target_t.size(0)\n",
        "        val_acc.append(100 * correct_t/total_t)\n",
        "        val_loss.append(batch_loss/len(test_loader))\n",
        "        network_learned = batch_loss < valid_loss_min\n",
        "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
        "\n",
        "        \n",
        "        if network_learned:\n",
        "            valid_loss_min = batch_loss\n",
        "            torch.save(resnet.state_dict(), 'resnet.pt')\n",
        "            print('Improvement-Detected, save-model')\n",
        "    resnet.train()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "best achieved validation accuracy of 28.4%, pretty good for just a single linear classification head ontop of such a small network (resnet 18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "37c0b2ad2c8869fec308ce425c074bfb626480a1d1a7dd847acd9e6b37d7f919"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
